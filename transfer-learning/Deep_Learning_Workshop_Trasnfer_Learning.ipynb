{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "nav_menu": {
      "height": "360px",
      "width": "416px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Deep Learning Workshop-Trasnfer Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRYGFOqf_Lh1",
        "colab_type": "text"
      },
      "source": [
        "# **Transfer Learning Code Tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US9U4RdX_Lh2",
        "colab_type": "text"
      },
      "source": [
        "_This notebook contains all the sample code for the Deep learning Workshop: Trasnfer Learning._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZTByn2R_Lh2",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbPudD_H_Lh3",
        "colab_type": "text"
      },
      "source": [
        "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWyKHQck_Lh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)\n",
        "    \n",
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) # batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW-vLGBpBUyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0927941-3c96-44e9-e21c-ac4db8ac841b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"TensorFlow version is \", tf.__version__)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version is  1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSlcpuNYFvX2",
        "colab_type": "text"
      },
      "source": [
        "Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gabbeut2Fxbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST (Exersise 1)\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88RcTBjFPhLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d03266f-c36b-40cb-a752-08709a8ffcf0"
      },
      "source": [
        "# Cats and Dogs (Exercise 2)\n",
        "zip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\",\n",
        "                                   fname=\"cats_and_dogs_filtered.zip\", extract=True)\n",
        "base_dir, _ = os.path.splitext(zip_file)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtH4jfU5AShZ",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35eQAKhzAVmp",
        "colab_type": "text"
      },
      "source": [
        "This exercise contains sample code from \"Hands-On Machine Learning with Scikit-Learn & Tensorflow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2laLxn6DEng2",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning w/ models saved from tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNdhketP_LjP",
        "colab_type": "text"
      },
      "source": [
        "Let's create a simple neural net (w/gradient clipping) and pretrain it on the MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdTz_W-hGP5Y",
        "colab_type": "text"
      },
      "source": [
        "First we will create and save a model that is pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iAbUAO2_LjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 * 28  # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 50\n",
        "n_hidden3 = 50\n",
        "n_hidden4 = 50\n",
        "n_hidden5 = 50\n",
        "n_outputs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkGRPitNDluO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsmlkiCz_LjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUd4Tr2Q_LjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 1.0\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "grads_and_vars = optimizer.compute_gradients(loss)\n",
        "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
        "              for grad, var in grads_and_vars]\n",
        "training_op = optimizer.apply_gradients(capped_gvs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDzZi6wL_LjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdE4USLf_LjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31jvOG-F_Ljb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 20\n",
        "batch_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1OTdPKa_Ljd",
        "colab_type": "code",
        "outputId": "559e99a4-d2bf-420b-fbc3-1362e2214913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Validation accuracy: 0.2878\n",
            "1 Validation accuracy: 0.7938\n",
            "2 Validation accuracy: 0.88\n",
            "3 Validation accuracy: 0.9064\n",
            "4 Validation accuracy: 0.9162\n",
            "5 Validation accuracy: 0.922\n",
            "6 Validation accuracy: 0.9294\n",
            "7 Validation accuracy: 0.936\n",
            "8 Validation accuracy: 0.938\n",
            "9 Validation accuracy: 0.9416\n",
            "10 Validation accuracy: 0.9458\n",
            "11 Validation accuracy: 0.9472\n",
            "12 Validation accuracy: 0.9476\n",
            "13 Validation accuracy: 0.9534\n",
            "14 Validation accuracy: 0.9566\n",
            "15 Validation accuracy: 0.9564\n",
            "16 Validation accuracy: 0.9578\n",
            "17 Validation accuracy: 0.9588\n",
            "18 Validation accuracy: 0.9622\n",
            "19 Validation accuracy: 0.9616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluWZsSOGbjK",
        "colab_type": "text"
      },
      "source": [
        "Next we will reuse the saved model and continue training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IxhJ5nh_Ljh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiLSL4VI_Ljl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM-0bRIE_Lju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
        "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
        "\n",
        "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
        "\n",
        "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFkQK8ub_Ljv",
        "colab_type": "text"
      },
      "source": [
        "When developing model, can create a collection containing all important operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUUASWWt_Ljv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for op in (X, y, accuracy, training_op):\n",
        "    tf.add_to_collection(\"my_important_ops\", op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJbgEBaX_Ljx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The when reusing model can simple use get_collection()\n",
        "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmQgtxcq_Ljy",
        "colab_type": "text"
      },
      "source": [
        "Now you can start a session, restore the model's state and continue training on your data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Eu_h5_v_Lj1",
        "colab_type": "code",
        "outputId": "d6129980-f74c-4417-9e33-2ff7b13c6fd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Validation accuracy: 0.9638\n",
            "1 Validation accuracy: 0.9634\n",
            "2 Validation accuracy: 0.9652\n",
            "3 Validation accuracy: 0.9648\n",
            "4 Validation accuracy: 0.9642\n",
            "5 Validation accuracy: 0.965\n",
            "6 Validation accuracy: 0.9692\n",
            "7 Validation accuracy: 0.9686\n",
            "8 Validation accuracy: 0.9682\n",
            "9 Validation accuracy: 0.9686\n",
            "10 Validation accuracy: 0.9702\n",
            "11 Validation accuracy: 0.9714\n",
            "12 Validation accuracy: 0.967\n",
            "13 Validation accuracy: 0.9698\n",
            "14 Validation accuracy: 0.971\n",
            "15 Validation accuracy: 0.9716\n",
            "16 Validation accuracy: 0.9718\n",
            "17 Validation accuracy: 0.9712\n",
            "18 Validation accuracy: 0.9712\n",
            "19 Validation accuracy: 0.9714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiBxvMqV_Lj6",
        "colab_type": "text"
      },
      "source": [
        "Now lets try to reload the model, but now only using the initial layers and replacing the last hidden layer (layer 4) and the output layer. We will also change the loss and optimizer for the new output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJgFDFr3_Lj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_hidden4 = 20  # new layer\n",
        "n_outputs = 10  # new layer\n",
        "\n",
        "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
        "\n",
        "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
        "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
        "\n",
        "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
        "\n",
        "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
        "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
        "\n",
        "with tf.name_scope(\"new_loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "with tf.name_scope(\"new_eval\"):\n",
        "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
        "\n",
        "with tf.name_scope(\"new_train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "new_saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ1X6U4n_Lj7",
        "colab_type": "text"
      },
      "source": [
        "And we can train this new model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJPUxilS_Lj8",
        "colab_type": "code",
        "outputId": "8e804b6f-8bfb-4130-bb02-8b9f8b984003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Validation accuracy: 0.9192\n",
            "1 Validation accuracy: 0.9394\n",
            "2 Validation accuracy: 0.9486\n",
            "3 Validation accuracy: 0.9528\n",
            "4 Validation accuracy: 0.9554\n",
            "5 Validation accuracy: 0.9556\n",
            "6 Validation accuracy: 0.9576\n",
            "7 Validation accuracy: 0.961\n",
            "8 Validation accuracy: 0.9612\n",
            "9 Validation accuracy: 0.9642\n",
            "10 Validation accuracy: 0.965\n",
            "11 Validation accuracy: 0.966\n",
            "12 Validation accuracy: 0.9638\n",
            "13 Validation accuracy: 0.9672\n",
            "14 Validation accuracy: 0.9688\n",
            "15 Validation accuracy: 0.9682\n",
            "16 Validation accuracy: 0.9702\n",
            "17 Validation accuracy: 0.9676\n",
            "18 Validation accuracy: 0.9694\n",
            "19 Validation accuracy: 0.9704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9WQZrSI_LkA",
        "colab_type": "text"
      },
      "source": [
        "### Transfer learning w/ weights from other frameworks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FOqh_iy_LkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 2\n",
        "n_hidden1 = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmGZHYv-_LkB",
        "colab_type": "code",
        "outputId": "f760ee2d-c1b6-40e8-de54-e75874785415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
        "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
        "# [...] Build the rest of the model\n",
        "\n",
        "# Get a handle on the assignment nodes for the hidden1 variables\n",
        "graph = tf.get_default_graph()\n",
        "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
        "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
        "init_kernel = assign_kernel.inputs[1]\n",
        "init_bias = assign_bias.inputs[1]\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
        "    # [...] Train the model on your new task\n",
        "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # not shown in the book"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 61.  83. 105.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iw1ptML_LkE",
        "colab_type": "text"
      },
      "source": [
        "Note that we could also get a handle on the variables using `get_collection()` and specifying the `scope`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ4HTjaY_LkE",
        "colab_type": "code",
        "outputId": "65feee50-511c-4698-d3e5-9ddcc6cada7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
              " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq1r6g-5_LkF",
        "colab_type": "text"
      },
      "source": [
        "Or we could use the graph's `get_tensor_by_name()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_RCrp1u_LkF",
        "colab_type": "code",
        "outputId": "9894d33c-dff9-4d27-de34-10fb55bbe41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfvshEq1_LkG",
        "colab_type": "code",
        "outputId": "d62a45e4-f153-4148-9948-a91d6b4f4c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8wZSAMUM_UQ",
        "colab_type": "text"
      },
      "source": [
        "### Train with Lower Layers locked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYrsW71IOSYd",
        "colab_type": "text"
      },
      "source": [
        "Training using no layers locked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSHcvpZL_LkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 * 28  # MNIST\n",
        "n_hidden1 = 300 # reused\n",
        "n_hidden2 = 50  # reused\n",
        "n_hidden3 = 50  # reused\n",
        "n_hidden4 = 20  # new!\n",
        "n_outputs = 10  # new!\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
        "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pivk_pbZ_LkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"train\"):                                         # not shown in the book\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     # not shown\n",
        "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
        "                                   scope=\"hidden[34]|outputs\")\n",
        "    training_op = optimizer.minimize(loss, var_list=train_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjFXhFFz_LkJ",
        "colab_type": "code",
        "outputId": "a283c3d8-9190-45bb-dd3a-a46f42e92daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                               scope=\"hidden[123]\") # regular expression\n",
        "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Validation accuracy: 0.8964\n",
            "1 Validation accuracy: 0.9304\n",
            "2 Validation accuracy: 0.9406\n",
            "3 Validation accuracy: 0.9446\n",
            "4 Validation accuracy: 0.9482\n",
            "5 Validation accuracy: 0.9508\n",
            "6 Validation accuracy: 0.9508\n",
            "7 Validation accuracy: 0.9536\n",
            "8 Validation accuracy: 0.9554\n",
            "9 Validation accuracy: 0.9566\n",
            "10 Validation accuracy: 0.956\n",
            "11 Validation accuracy: 0.9572\n",
            "12 Validation accuracy: 0.9572\n",
            "13 Validation accuracy: 0.958\n",
            "14 Validation accuracy: 0.9586\n",
            "15 Validation accuracy: 0.9576\n",
            "16 Validation accuracy: 0.9578\n",
            "17 Validation accuracy: 0.96\n",
            "18 Validation accuracy: 0.9592\n",
            "19 Validation accuracy: 0.9602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi5jFUBgOYbE",
        "colab_type": "text"
      },
      "source": [
        "Now lets lock the first 3 hidden layers and only train the last hidden layer and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UYdLiUl_LkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28 * 28  # MNIST\n",
        "n_hidden1 = 300 # reused\n",
        "n_hidden2 = 50  # reused\n",
        "n_hidden3 = 50  # reused\n",
        "n_hidden4 = 20  # new!\n",
        "n_outputs = 10  # new!\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmCzwKbu_LkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
        "                              name=\"hidden1\") # reused frozen\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
        "                              name=\"hidden2\") # reused frozen\n",
        "    hidden2_stop = tf.stop_gradient(hidden2)\n",
        "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
        "                              name=\"hidden3\") # reused, not frozen\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
        "                              name=\"hidden4\") # new!\n",
        "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH3YHABW_LkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQem3yDk_LkP",
        "colab_type": "text"
      },
      "source": [
        "The training code is exactly the same as earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1QqGdNj_LkQ",
        "colab_type": "code",
        "outputId": "d5a775b6-d804-48cf-88e6-49f1f8b8633e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                               scope=\"hidden[123]\") # regular expression\n",
        "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Validation accuracy: 0.9024\n",
            "1 Validation accuracy: 0.9304\n",
            "2 Validation accuracy: 0.943\n",
            "3 Validation accuracy: 0.9476\n",
            "4 Validation accuracy: 0.9514\n",
            "5 Validation accuracy: 0.9522\n",
            "6 Validation accuracy: 0.9522\n",
            "7 Validation accuracy: 0.9556\n",
            "8 Validation accuracy: 0.9554\n",
            "9 Validation accuracy: 0.9564\n",
            "10 Validation accuracy: 0.9568\n",
            "11 Validation accuracy: 0.955\n",
            "12 Validation accuracy: 0.9574\n",
            "13 Validation accuracy: 0.9578\n",
            "14 Validation accuracy: 0.9582\n",
            "15 Validation accuracy: 0.957\n",
            "16 Validation accuracy: 0.9566\n",
            "17 Validation accuracy: 0.9582\n",
            "18 Validation accuracy: 0.9592\n",
            "19 Validation accuracy: 0.9578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msl55KIgOr_7",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1fL1L4IO5Ez",
        "colab_type": "text"
      },
      "source": [
        "This exercise contains sample code from TensorFlow's Tutorial \"Transfer Learning Using Pretrained ConvNets\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIMZB4ISRW7L",
        "colab_type": "text"
      },
      "source": [
        "We will perform transfer learning on the cats/dogs dataset with a CNN model (MobileNet V2) that is pre-trained on the ImageNet dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge9eMKYfQF48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d917cc3-340d-4612-dd02-10dbf9d999a2"
      },
      "source": [
        "# Create the training and validation directories for cats datasets and dog datasets\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "print ('Total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "print ('Total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "print ('Total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "print ('Total validation dog images:', len(os.listdir(validation_dogs_dir)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training cat images: 1000\n",
            "Total training dog images: 1000\n",
            "Total validation cat images: 500\n",
            "Total validation dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOhD7szMQRTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "343f8777-b088-4743-988a-6f84fb87eb2a"
      },
      "source": [
        "# Define data generator to augmentat the dataset\n",
        "\n",
        "image_size = 160 # All images will be resized to 160x160\n",
        "batch_size = 32\n",
        "\n",
        "# Rescale all images by 1./255 and apply image augmentation\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "                rescale=1./255)\n",
        "\n",
        "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                train_dir,  # Source directory for the training images\n",
        "                target_size=(image_size, image_size),\n",
        "                batch_size=batch_size,\n",
        "                # Since we use binary_crossentropy loss, we need binary labels\n",
        "                class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                validation_dir, # Source directory for the validation images\n",
        "                target_size=(image_size, image_size),\n",
        "                batch_size=batch_size,\n",
        "                class_mode='binary')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfwHyYICTway",
        "colab_type": "text"
      },
      "source": [
        "## Use pre-trained Feature Extractor Only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRjzXTDFR7xT",
        "colab_type": "text"
      },
      "source": [
        "We will first download and load the pre-trained model and freeze its weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5obyAe6QlB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5cfabcd3-4210-4f04-9e73-cfe261fcd378"
      },
      "source": [
        "# Create base mobel from pre-trained MobileNet V2\n",
        "IMG_SHAPE = (image_size, image_size, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkriG08VRmPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzyPbOeVRt8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30fcba16-e73d-4284-bb16-01e124b730e7"
      },
      "source": [
        "# View the structure of our model\n",
        "base_model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenetv2_1.00_160\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_pad (ZeroPadding2D)       (None, 161, 161, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv1 (Conv2D)                  (None, 80, 80, 32)   864         Conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_Conv1 (BatchNormalization)   (None, 80, 80, 32)   128         Conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Conv1_relu (ReLU)               (None, 80, 80, 32)   0           bn_Conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise (Depthw (None, 80, 80, 32)   288         Conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_BN (Bat (None, 80, 80, 32)   128         expanded_conv_depthwise[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_depthwise_relu (R (None, 80, 80, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project (Conv2D)  (None, 80, 80, 16)   512         expanded_conv_depthwise_relu[0][0\n",
            "__________________________________________________________________________________________________\n",
            "expanded_conv_project_BN (Batch (None, 80, 80, 16)   64          expanded_conv_project[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand (Conv2D)         (None, 80, 80, 96)   1536        expanded_conv_project_BN[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_BN (BatchNormali (None, 80, 80, 96)   384         block_1_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_expand_relu (ReLU)      (None, 80, 80, 96)   0           block_1_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_pad (ZeroPadding2D)     (None, 81, 81, 96)   0           block_1_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise (DepthwiseCon (None, 40, 40, 96)   864         block_1_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_BN (BatchNorm (None, 40, 40, 96)   384         block_1_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_depthwise_relu (ReLU)   (None, 40, 40, 96)   0           block_1_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project (Conv2D)        (None, 40, 40, 24)   2304        block_1_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_1_project_BN (BatchNormal (None, 40, 40, 24)   96          block_1_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand (Conv2D)         (None, 40, 40, 144)  3456        block_1_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_2_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_2_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise (DepthwiseCon (None, 40, 40, 144)  1296        block_2_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_BN (BatchNorm (None, 40, 40, 144)  576         block_2_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_depthwise_relu (ReLU)   (None, 40, 40, 144)  0           block_2_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project (Conv2D)        (None, 40, 40, 24)   3456        block_2_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_2_project_BN (BatchNormal (None, 40, 40, 24)   96          block_2_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 40, 40, 24)   0           block_1_project_BN[0][0]         \n",
            "                                                                 block_2_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand (Conv2D)         (None, 40, 40, 144)  3456        block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_3_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_3_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_pad (ZeroPadding2D)     (None, 41, 41, 144)  0           block_3_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise (DepthwiseCon (None, 20, 20, 144)  1296        block_3_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_BN (BatchNorm (None, 20, 20, 144)  576         block_3_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_depthwise_relu (ReLU)   (None, 20, 20, 144)  0           block_3_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project (Conv2D)        (None, 20, 20, 32)   4608        block_3_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_3_project_BN (BatchNormal (None, 20, 20, 32)   128         block_3_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand (Conv2D)         (None, 20, 20, 192)  6144        block_3_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_4_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_4_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_4_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_4_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_4_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_4_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_4_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project (Conv2D)        (None, 20, 20, 32)   6144        block_4_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_4_project_BN (BatchNormal (None, 20, 20, 32)   128         block_4_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_add (Add)               (None, 20, 20, 32)   0           block_3_project_BN[0][0]         \n",
            "                                                                 block_4_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand (Conv2D)         (None, 20, 20, 192)  6144        block_4_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_5_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_5_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_5_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_5_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_5_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_5_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_5_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project (Conv2D)        (None, 20, 20, 32)   6144        block_5_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_5_project_BN (BatchNormal (None, 20, 20, 32)   128         block_5_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_add (Add)               (None, 20, 20, 32)   0           block_4_add[0][0]                \n",
            "                                                                 block_5_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand (Conv2D)         (None, 20, 20, 192)  6144        block_5_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_6_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_6_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_6_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_pad (ZeroPadding2D)     (None, 21, 21, 192)  0           block_6_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise (DepthwiseCon (None, 10, 10, 192)  1728        block_6_pad[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_BN (BatchNorm (None, 10, 10, 192)  768         block_6_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_6_depthwise_relu (ReLU)   (None, 10, 10, 192)  0           block_6_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project (Conv2D)        (None, 10, 10, 64)   12288       block_6_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_6_project_BN (BatchNormal (None, 10, 10, 64)   256         block_6_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand (Conv2D)         (None, 10, 10, 384)  24576       block_6_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_7_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_7_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_7_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_7_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_7_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_7_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_7_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project (Conv2D)        (None, 10, 10, 64)   24576       block_7_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_7_project_BN (BatchNormal (None, 10, 10, 64)   256         block_7_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_7_add (Add)               (None, 10, 10, 64)   0           block_6_project_BN[0][0]         \n",
            "                                                                 block_7_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand (Conv2D)         (None, 10, 10, 384)  24576       block_7_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_8_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_8_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_8_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_8_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_8_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_8_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_8_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project (Conv2D)        (None, 10, 10, 64)   24576       block_8_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_8_project_BN (BatchNormal (None, 10, 10, 64)   256         block_8_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_8_add (Add)               (None, 10, 10, 64)   0           block_7_add[0][0]                \n",
            "                                                                 block_8_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand (Conv2D)         (None, 10, 10, 384)  24576       block_8_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_9_expand[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_9_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_9_expand_BN[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_9_expand_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_9_depthwise[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_9_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_9_depthwise_BN[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project (Conv2D)        (None, 10, 10, 64)   24576       block_9_depthwise_relu[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block_9_project_BN (BatchNormal (None, 10, 10, 64)   256         block_9_project[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_9_add (Add)               (None, 10, 10, 64)   0           block_8_add[0][0]                \n",
            "                                                                 block_9_project_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand (Conv2D)        (None, 10, 10, 384)  24576       block_9_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_BN (BatchNormal (None, 10, 10, 384)  1536        block_10_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_10_expand_relu (ReLU)     (None, 10, 10, 384)  0           block_10_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise (DepthwiseCo (None, 10, 10, 384)  3456        block_10_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_BN (BatchNor (None, 10, 10, 384)  1536        block_10_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_10_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           block_10_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project (Conv2D)       (None, 10, 10, 96)   36864       block_10_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_10_project_BN (BatchNorma (None, 10, 10, 96)   384         block_10_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand (Conv2D)        (None, 10, 10, 576)  55296       block_10_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_11_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_11_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_11_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_11_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_11_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_11_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_11_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project (Conv2D)       (None, 10, 10, 96)   55296       block_11_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_11_project_BN (BatchNorma (None, 10, 10, 96)   384         block_11_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_11_add (Add)              (None, 10, 10, 96)   0           block_10_project_BN[0][0]        \n",
            "                                                                 block_11_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand (Conv2D)        (None, 10, 10, 576)  55296       block_11_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_12_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_12_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_12_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_12_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_12_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_12_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_12_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project (Conv2D)       (None, 10, 10, 96)   55296       block_12_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_12_project_BN (BatchNorma (None, 10, 10, 96)   384         block_12_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_12_add (Add)              (None, 10, 10, 96)   0           block_11_add[0][0]               \n",
            "                                                                 block_12_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand (Conv2D)        (None, 10, 10, 576)  55296       block_12_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_13_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_13_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_13_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_pad (ZeroPadding2D)    (None, 11, 11, 576)  0           block_13_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise (DepthwiseCo (None, 5, 5, 576)    5184        block_13_pad[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_BN (BatchNor (None, 5, 5, 576)    2304        block_13_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_13_depthwise_relu (ReLU)  (None, 5, 5, 576)    0           block_13_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project (Conv2D)       (None, 5, 5, 160)    92160       block_13_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_13_project_BN (BatchNorma (None, 5, 5, 160)    640         block_13_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand (Conv2D)        (None, 5, 5, 960)    153600      block_13_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_14_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_14_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_14_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_14_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_14_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_14_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_14_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project (Conv2D)       (None, 5, 5, 160)    153600      block_14_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_14_project_BN (BatchNorma (None, 5, 5, 160)    640         block_14_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_14_add (Add)              (None, 5, 5, 160)    0           block_13_project_BN[0][0]        \n",
            "                                                                 block_14_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand (Conv2D)        (None, 5, 5, 960)    153600      block_14_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_15_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_15_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_15_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_15_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_15_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_15_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_15_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project (Conv2D)       (None, 5, 5, 160)    153600      block_15_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_15_project_BN (BatchNorma (None, 5, 5, 160)    640         block_15_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block_15_add (Add)              (None, 5, 5, 160)    0           block_14_add[0][0]               \n",
            "                                                                 block_15_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand (Conv2D)        (None, 5, 5, 960)    153600      block_15_add[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_16_expand[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_16_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_16_expand_BN[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_16_expand_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_16_depthwise[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block_16_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_16_depthwise_BN[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project (Conv2D)       (None, 5, 5, 320)    307200      block_16_depthwise_relu[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block_16_project_BN (BatchNorma (None, 5, 5, 320)    1280        block_16_project[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1 (Conv2D)                 (None, 5, 5, 1280)   409600      block_16_project_BN[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Conv_1_bn (BatchNormalization)  (None, 5, 5, 1280)   5120        Conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "out_relu (ReLU)                 (None, 5, 5, 1280)   0           Conv_1_bn[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF83o_EVSOt9",
        "colab_type": "text"
      },
      "source": [
        "Now let us add a new classification layer to the model for the cats/dogs dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r9t0Ml3SV_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  keras.layers.GlobalAveragePooling2D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3NMKq2tSjDI",
        "colab_type": "text"
      },
      "source": [
        "As ususal we compile our model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLu11OfaSrND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "ae2dad16-e713-4f41-d993-e262d26e6c6d"
      },
      "source": [
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "len(model.trainable_variables)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0827 18:17:39.947591 139821460305792 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_160 (Model) (None, 5, 5, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFDctzN8TRRc",
        "colab_type": "text"
      },
      "source": [
        "Now we will train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn1Ea7SGTUJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1fd5d791-d554-42bd-8fcd-04e125397ed7"
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs,\n",
        "                              workers=4,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_steps)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "62/62 [==============================] - 11s 185ms/step - loss: 0.6174 - acc: 0.6636 - val_loss: 0.4744 - val_acc: 0.8075\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 7s 114ms/step - loss: 0.4994 - acc: 0.7754 - val_loss: 0.3819 - val_acc: 0.8649\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 7s 114ms/step - loss: 0.4105 - acc: 0.8425 - val_loss: 0.3181 - val_acc: 0.8881\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 7s 113ms/step - loss: 0.3642 - acc: 0.8770 - val_loss: 0.2956 - val_acc: 0.8901\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 7s 117ms/step - loss: 0.3172 - acc: 0.8913 - val_loss: 0.2632 - val_acc: 0.9022\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 7s 112ms/step - loss: 0.2992 - acc: 0.8918 - val_loss: 0.2337 - val_acc: 0.9113\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 7s 114ms/step - loss: 0.2602 - acc: 0.9116 - val_loss: 0.2282 - val_acc: 0.9113\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 7s 113ms/step - loss: 0.2535 - acc: 0.9123 - val_loss: 0.2202 - val_acc: 0.9113\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 7s 113ms/step - loss: 0.2436 - acc: 0.9103 - val_loss: 0.2049 - val_acc: 0.9183\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 7s 114ms/step - loss: 0.2160 - acc: 0.9315 - val_loss: 0.2194 - val_acc: 0.9093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swE0qyiSUMLL",
        "colab_type": "text"
      },
      "source": [
        "Visualize Learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UNGC1Q8UN-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "a7327500-d560-4f68-a0e8-a2598398d887"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAHlCAYAAABoLv9VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOpQNkNlUUiC",
        "colab_type": "text"
      },
      "source": [
        "## Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r89KlcW3Uqv_",
        "colab_type": "text"
      },
      "source": [
        "We will now try fine-tuning the higher-level features of our pre-trained model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZs6QMGrUZO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15f2faad-a595-4482-9cde-b7228204cd8e"
      },
      "source": [
        "base_model.trainable = True\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdrYFl-aU54U",
        "colab_type": "text"
      },
      "source": [
        "Similar to above we compile our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ied5E_bU-jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9762d1fe-2ae6-4b99-9aad-73e2c704effd"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=2e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "len(model.trainable_variables)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_160 (Model) (None, 5, 5, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,863,873\n",
            "Non-trainable params: 395,392\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zQCywBRVG-C",
        "colab_type": "text"
      },
      "source": [
        "Similar to above we train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV0-iXB8VJ9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d0b1a036-05b8-4040-c1e8-68a66f08ab3e"
      },
      "source": [
        "history_fine = model.fit_generator(train_generator,\n",
        "                                   steps_per_epoch = steps_per_epoch,\n",
        "                                   epochs=epochs,\n",
        "                                   workers=4,\n",
        "                                   validation_data=validation_generator,\n",
        "                                   validation_steps=validation_steps)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "62/62 [==============================] - 12s 193ms/step - loss: 0.1585 - acc: 0.9461 - val_loss: 0.1199 - val_acc: 0.9597\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 7s 120ms/step - loss: 0.0843 - acc: 0.9731 - val_loss: 0.1192 - val_acc: 0.9567\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 7s 120ms/step - loss: 0.0582 - acc: 0.9868 - val_loss: 0.1125 - val_acc: 0.9587\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 7s 121ms/step - loss: 0.0483 - acc: 0.9863 - val_loss: 0.0976 - val_acc: 0.9688\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 7s 120ms/step - loss: 0.0253 - acc: 0.9949 - val_loss: 0.0957 - val_acc: 0.9688\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 8s 121ms/step - loss: 0.0185 - acc: 0.9949 - val_loss: 0.1031 - val_acc: 0.9677\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 8s 121ms/step - loss: 0.0139 - acc: 0.9985 - val_loss: 0.0983 - val_acc: 0.9708\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 8s 121ms/step - loss: 0.0145 - acc: 0.9975 - val_loss: 0.0932 - val_acc: 0.9708\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 8s 121ms/step - loss: 0.0106 - acc: 0.9985 - val_loss: 0.1027 - val_acc: 0.9698\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 8s 122ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1293 - val_acc: 0.9708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VolvvQfIVOGs",
        "colab_type": "text"
      },
      "source": [
        "Visualize learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAmx7PPuVRTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "b2c029ab-e6e4-48d7-f76f-f1946346b1f9"
      },
      "source": [
        "acc += history_fine.history['acc']\n",
        "val_acc += history_fine.history['val_acc']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.9, 1])\n",
        "plt.plot([epochs-1,epochs-1], plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 0.2])\n",
        "plt.plot([epochs-1,epochs-1], plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHlCAYAAAD2ooUEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8VFXawPHfk0JCCi0BQg/SSSWw\nKCICUmWtFOkK6KK4rm11dS0r+upa1ldRX9eyq6gIQaygCCqiK6wKJkjvYIBACCSB9J7z/nEnYRIm\nITCTTMrz/Xzmk5l7z5z7zCTw3HPuueeIMQallFJKNTwe7g5AKaWUUjVDk7xSSinVQGmSV0oppRoo\nTfJKKaVUA6VJXimllGqgNMkrpZRSDZQmedWoiYiniGSJSGdXlnUnEekuIjVyb2zFukXkaxGZXhNx\niMijIvL6hb5fKaVJXtUztiRb+igRkVy71w6TTVWMMcXGmABjzGFXlq2rRGSNiPzNwfYJInJURDzP\npz5jzGhjzGIXxDVSRBIq1P0/xpjbnK37HMc0IvLnmjqGUu6mSV7VK7YkG2CMCQAOA1fbbTsr2YiI\nV+1HWae9C8x0sH0m8L4xpriW43Gnm4A04MbaPrD+XaraokleNSgi8qSIfCAisSKSCcwQkUEi8rOI\nnBaRJBF5WUS8beW9bK25UNvr9237V4lIpoj8JCJdz7esbf+VIrJXRNJF5BUR+a+IzKok7urEeKuI\n7BeRUyLyst17PUXkRRFJFZGDwNgqvqJPgBARudTu/UHAOOA92+trRGSziGSIyGERebSK73t96Wc6\nVxwicouI7LJ9VwdE5Bbb9ubA50Bnu16ZNrbf5Tt2779eRHbYvqO1ItLLbl+iiNwrItts33esiPhU\nEXcgMB64HegrItEV9l9u+32ki8gREZlp2+5n+4yHbft+EBEfRz0RtpiG2Z6f19+l7T0Rtp6XNBE5\nLiJ/EZEOIpIjIi3syg207dcTB3UWTfKqIboeWAI0Bz4AioC7gGBgMFbyubWK908DHgVaYfUW/M/5\nlhWRNsAy4H7bcX8DBlZRT3ViHAf0B/phJYmRtu3zgNFAFPA74IbKDmKMyQY+onzrdQqw1Rizw/Y6\nC5gOtACuBu4SkauqiL3UueJIBn4PNAP+ALwiIpHGmHTbcQ7b9cqcsH+jiPQBFgF/AloDa4AV9knR\ndrxRwEVY35OjHotSE4FTwIe2um6yO1ZX4EvgBSAI6/veZtv9IhAJXIz1O38IKKnyWzmj2n+XthOf\nNVgnP+2AnsD3xpijwHpgkl29M4FYY0xRNeNQjYgmedUQrTfGfG6MKTHG5BpjfjHGbDDGFBljDgJv\nAkOreP9Hxpg4Y0whsBiIvoCyVwGbjTHLbfteBFIqq6SaMT5tjEk3xiQA39sd6wbgRWNMojEmFXim\ninjB6rK/wa6le6NtW2ksa40xO2zf3xZgqYNYHKkyDtvv5KCxrAW+BYZUo16wTkRW2GIrtNXdHCvZ\nllpgjDluO/YXVP17uwlYaowpwUq80+xawjOAVcaYZbbfR4oxZrNY4xVmAXcaY5JsYzTW2+KpjvP5\nu7wG66TnJWNMvjEmwxiz0bbvXVuMpd3+U7BOgJQ6iyZ51RAdsX8hIr1FZKWtSzMDeAKr9VSZ43bP\nc4CACyjb3j4OY60ElVhZJdWMsVrHAg5VES/Af4AM4GoR6YnVUo21i2WQiHwvIidFJB24xUEsjlQZ\nh4hcJSIbbN3Pp7Fa/dWpt7TusvpsyTkR6GBXplq/N7Eut1yOdVIG8KmtbOnlhU7AAQdvbQs0qWRf\ndZzP32VlMZTGGyXWXR5jgRPGmE0XGJNq4DTJq4ao4m1bbwDbge7GmGbA3wCp4RiSgI6lL0REKJ+Q\nKnImxiSspFCqylv8bCcc72G14GcCXxpj7HsZlgIfA52MMc2Bf1czlkrjEJGmWJcJngbaGmNaAF/b\n1XuuW+2OAV3s6vPA+n6PViOuim60HXeViBwH9mMl79Iu+yNANwfvSwYKKtmXDfjZxeeF1dVv73z+\nLiuLAWNMDtbvZzrW709b8apSmuRVYxAIpAPZtmu7VV2Pd5UvgBgRudr2H/5dWNeSayLGZcDdtkFZ\nQcAD1XjPe1itwDnYddXbxZJmjMkTkUuwuoOdjcMHK5GeBIpt1/hH2O1PBoJtA+Iqq/saERlmuw5/\nP5AJbKhmbPZuxEqo0XaPyVg9Gy2B94GxYt1W6CUiwSISZbvz4B1ggYiE2AYaDrbFsxsIFJExtteP\nAd4Ojm2vqt/5CqyBiHfYBvY1ExH7MR3vYf3ufm+LVymHNMmrxuDPWK20TKzW0wc1fUBjTDJW4ngB\nSMVqlf0K5NdAjK9hXd/eBvyC1WI+V3z7gY1YyXdlhd3zgKdto8AfwkqwTsVhjDkN3IPV1ZyGNfDt\nC7v927Fapwm20eZtKsS7A+v7eQ3rRGEscM15XA8HQEQuw+r6f9V2/f64Mea4La4EYLIx5jesgYAP\n2GLdBETYqrgH2AXE2/b9HRBjzCmsQYHvYvUupFH+8oEjlf7ObYMRRwETsE6A9lJ+XMQPgBewwRhT\n6WUgpcTquVNK1STboK1jwERjzDp3x6PqPxH5AXjbGPOOu2NRdZe25JWqISIyVkRa2EaxPwoUYrWe\nlXKK7TJKONYtgEpVyukkb7tmFCci+WI3cUUlZe8pHUkqIm/bT1YhIqEi8p1toofddvcAK1VfXQYc\nxOpeHgNcb4yprLteqWoRkcXAauAu27wHSlXK6e56ERmPNRnEGKCpMWZWJeXGYA0WuQKr2/JT4Gdj\nzIO2/T8BPwEPY0368RbQwxhz0qkAlVJKqUbKZdfkReRJoGMVSX4JkGCMecj2egSw2BgTYrtXdxsQ\nbIzJtO1fZ9uvq1AppZRSF6A2r8mHAVvsXm8B2tputQkDDpYmeLv9YbUYn1JKKdWg1OaCBgFY94SW\nKn0e6GBf6X6Hk4eIyFxgLoC/v3//3r17uzZSpRqphIwEAEKbhbo1DqXqqhIDBUXFFBSVkF9UQkFx\nSdnzwuLyyxh4itDEywMfLw/at2iKp4fr5uCKj49PMcZUNfcGULtJPgtrYYpSpc8zHewr3Z+JA8aY\nN7HmeWbAgAEmLi7OtZEq1UjNXj0bgIVjF7o5EqXcJyu/iEOp2RxKzSEhNZtDKbafqTkcz8grKydA\nO/8mdAnyIzTI/6yfLf2b1FiMInKu6auB2k3yO7BWpyqdWCMKSDbGpIrIDuAiEQm067KPwlo4Qiml\nVD1TUFTCf/en8OW2JPYmZxIU4EPrAB9aB555tLF77tek5tNRXmExKVn5nMy0HidsP0/abUs8lUtK\nVvmbYIIDfAgN8mNw92BCg/zoEuxv/WzlT3O/c01s6F5Of6u2KTu9AE/AU0R8gSIHyx6+B7xju/3j\nGPAI1hSRGGP2ishm4DEReQS4Ems5xwnOxqeUUqp25BUWs35fCl9uT+Kbnclk5hUR6ONFZKfmJGfk\nsf1oOilZ+ZQ4GO/t38Sz3AlAxROC1gG+tA70ISigCd6eZ4aTFZcY0rILzkrWZ17nlb3OyHO8Gm+Q\nf5Oy4wzv1ZrQYP8zLfJgfwJ8arM97FquiPwRrHmaS80AHheRt4GdQF9jzGFjzGoReQ74DmiKNYWl\n/fumYCX9U1jrck/U2+eUUqpuyyss5j97T7JqWxJrdp0gK7+IZr5ejAkLYVxECIO7B+Pj5VlWvrjE\ncCqnwEEyLm1Z57HneCbrM1MqTcqt/JvQ0s+bzLwiUrMLKHZw1mB/0tArJJDLugdX66ShoXE6yRtj\n5gPzK9ldbqlHY8wLWHN5O6onARjmbDxKKaVqVm5BMd/vOcHKbUms3X2CnIJiWvh58/uIdoyLbMeg\ni4Jo4uU4cXp6CMEBPgQH+NCnXdXHqdi9bt9ST8suoHlTb4ct/+AAH/zrcevblfRbUEopdU7Z+UV8\nt+cEX25L4rvdJ8ktLCbIvwnX9evAuPB2XHxRK5e3iH29PenY0o+OLf3OXVg5pEleKaWUQ5l5hazd\nbSX27/ecJL+ohOAAHyb278iVESEMDG2FVwPu6m4INMkrpZQqk55byLe7kvly23F+2HeSgqIS2jbz\nYerAzlwZHsKA0FYuvd9b1SxN8kopVc/8evgU//hqD9kFxS6tt6TEsPt4BoXFhnbNfZlxcRfGRYQQ\n07klHprY6yVN8kopVY988MthHv1sB0EBTejZNtDl9c+6NJRxEe2I6thCE3sDoEleKaXqgYKiEh7/\nfAeLNxxmSI9gXpnajxZ+NTejmmoYNMkrpVQddyIjj3mLNxF/6BS3Dr2Iv4zprdfFVbVokldKqTps\n0+FTzHs/nozcIl6Z2o+ro9q7OyRVj2iSV0qpOmrpxsP8bfkOQpr78sntA+nTruI6XkpVTZO8UkrV\nMXr9XbmKJnmllKpD7K+/3za0G/eP6aXX39UF0ySvlFJ1RPwh6/p7Zl4R/zetH1dF6vV35RxN8kop\nVQfEbjzM35Zvp13zprx380B6h+j1d+U8TfJKKeVGBUUlzP98B0s2HObynq15eUq0Xn9XLqNJXiml\n3MT++vu8Yd24b7Ref1eupUleKaXcwP76+6vTYvh95DkWV1fqAmiSV0qpWrZkw2EeW6HX31XN0ySv\nlFK1JL+omPkrdhK7Ua+/q9qhSV4ppWrBiYw8bns/nk2HT3P7sG78Wa+/q1qgSV4ppYDiEsNzq3fz\nW0o2/j5e+DXxPPOziRd+Praf9tsr7G/i6YHI2Yk7/lAa897fRFZ+Ef+cHsO4CL3+rmqHJnmllAKe\n/3oPb/xwkB5tAsgvKiGnoIjs/GJyC4urXYeXhzg8CYg/dIr2LZqy6OaL6RXi+jXglaqMJnmlVKO3\nensSr31/gKkDO/P0+Ihy+4pLDLmFxeTkF5FdUEx2fhE5BcVkFxSRk2+9zi6wbcuv8NNW5urI9jx2\ndRjN/bzd9AlVY6VJXinVqO0/kcWfl20hqlML5l/T96z9nh5CgI8XAT7636WqfzzcHYBSSrlLZl4h\nty6Kw9fbk9dnxODj5enukJRyKT01VUo1SsYY7v9wKwmpObx/88W0a97U3SEp5XLakldKNUqv/+cg\nq3cc569X9mZQtyB3h6NUjdAkr5RqdNbvS+EfX+3mqsh23HxZV3eHo1SN0SSvlGpUEk/l8KfYTXRv\nE8CzEyId3teuVEOhSV4p1WjkFRZz2/vxFBUb3pg5AH8dMa8aOP0LV0o1CsYYHv1sO9uPZvDvGwfQ\nNdjf3SEpVeOcbsmLSCsR+VREskXkkIhMq6RcCxF5V0RO2B7zK+yPFpF1IpIuIoki8qizsSmlVKkl\nGw/zYXwid17RnZF927o7HKVqhSta8q8CBUBbIBpYKSJbjDE7KpR7EfADQoE2wLcicsgYs9C2fwnw\nKTDMVma9rZ4VLohRKdWIbTp8ivkrdjC0Z2vuGtnT3eEoVWucasmLiD8wAXjUGJNljFkPrABmOih+\nNfCcMSbHGJMAvAXMsdsfCiw2xhQbYw4A64EwZ+JTSqmTmfnMez+ekOa+vDQlWld+U42Ks931PYEi\nY8xeu21bqDw5S4Xn4XavFwA3ioi3iPQCBgFrHFYiMldE4kQk7uTJkxcevVKqQSssLuGOJZtIzy3k\njRkDdO121eg4m+QDgIwK29IBR8ssrQYeFJFAEemO1Yr3s9v/BTARyAV2A28ZY35xdFBjzJvGmAHG\nmAGtW7d28iMopRqqZ1btZsNvaTw9PoK+7Zu5Oxylap2zST4LqPgvpxmQ6aDsnVgJfB+wHIgFEsEa\nvId1EvAE4At0AsaIyO1OxqeUaqRWbDnGW+t/Y9aloVzfr6O7w1HKLZxN8nsBLxHpYbctCqg46A5j\nTJoxZroxJsQYE2Y79kbb7ouAYmPMe8aYImNMIrAUGOdkfEqpRmj38Qwe+GgrA7q05KFxfdwdjlJu\n41SSN8ZkA58AT4iIv4gMBq4FFlUsKyLdRCRIRDxF5EpgLvCkbfdeq4hMExEPEQkBJgNbnYlPKdX4\npOcWcuuieAJ8vfjn9BiaeOmcX6rxcsVf/+1AU+AEVhf8PGPMDhEZIiJZduX6A9uwuvKfBqaX3mZn\njMkAxgP3AKeAzcB2zpwEKKXUOZWUGO79YDNHT+Xy2vQY2jTzdXdISrmV0/fJG2PSgOscbF+HNTCv\n9PUyYFkV9awFfudsPEqpxuuVtfv5dvcJHr8mjAGhrdwdjlJup/1YSqkG4bvdJ1jw7V7G9+vAjYO6\nuDscpeoETfJKqXrvUGo2dy39lT4hzXjq+ghdWU4pG03ySql6LbegmFsXxSMivDGzP02beLo7JKXq\nDF2FTilVbxljePCTrexJzmThrN/RqZXfud+kVCOiLXmlVL31zo8JLN98jHtH9mRYrzbuDkepOkeT\nvFKqXtr4WxpPrdzFyD5t+ePw7u4OR6k6SZO8UqreOZmZz+2LN9GplR8vTI7CQ1eWU8ohvSavlKp3\n3vspgdTsfN6/ZSDNfL3dHY5SdZa25JVS9UphcQkf/HKEYT1b0ztEV5ZTqiqa5JVS9cra3Sc4kZnP\ntIt1whulzkW765VS9cqSDYcJaebL8F6t3R2Kqg5joDCnBioW8G4KdX3iI2Mg7zQ0bemWw2uSV0rV\nG0fScvhh30n+dEUPvDy1I7LOys+E336A/Wusx+nDNXMcr6YQ0BoC2toebcr/9G9je97GOiFwpYJs\nyDpheyTbHifO/My221dcAA8dgyb+ro2hGjTJK6XqjaW/HEaAKb/r5O5QlL2SEkjeBvu/tR5HfoaS\nImgSAF0vh5ibwNPFAyRLiiE37UwiTTsIh3+CnFTH5X2aVzgJaGP32u7EoKTYqi/7pOPkXfqzIMvB\nQQT8W5+pL7jXmXrdRJO8UqpeKCwuYVlcIsN7taF9Cxe3ytT5y06BA99ZLfUDa62WK0BIBFz6J+g2\nAjpdDF5Najeu4kIrtnJJ2e559kk4vtV6nZ9RvTp9m585GWjf7+xeA3/bc78g8KxbabVuRaOUUpX4\ndlcyJzPzmTqws7tDOX95GYBxbZ3iYbWUa+uadHERHI070wV/bDNgoGkr6HYFdB9p/Qx0X6sVsHoM\nmrWzHudSkFO+Wz0r2fpeA0LsEnhr8Pat+bhriCZ5pVS9sHjDYdo192VYfRpwV5ADH98Me76smfo9\nmzi+Fm3fDV3afdzkAub1T0+0dcGvgYP/gfx0Kwl2HAjDH4LuI6BdNHjU00WBmvhBk1BoGeruSGqM\nJnmlVJ13JC2HdftSuHtkPRpwl5cOS6ZY14kvvRMCQ1xbf0mRdf25tBV6+jAk/mJ1VTvqNWgSWMXJ\nQJszrdaTe6zu9/1r4ORu673NOkDYtVYX/EVD3TZSXJ0/TfJKqTovduNhPAQm15cBd9kpsOh6OLET\nJr4F4RNq79jFpcm/kmvSWScgeYd1PT0/3XEdnj7Q5VLoN9Pqhm/dq+7fqqYc0iSvlKrTSgfcXdG7\nDe2a14MBd+mJ8N511s+pS6HHqNo9vqeXdV28OtfGC3Ntt3vZjSRv1hFCL7uw7n1V52iSV0rVad/s\nTCYlK59pF9eDAXcp++G9a61R2zM/hS6D3B1R1bybQssu1kM1SJrklVJ1WuzGw7Rv7svQnnV8vfik\nLbBovPV81hfQLsq98SiFzl2vlKrDDqVms25fCpN/1xnPuryc7KGf4J2rwMsX5nylCV7VGZrklVJ1\nVuzGI3h6SN0ecLfvG2uQXUBbuPkrCO7u7oiUKqNJXilVJxUUlfBR/BGu6N2GkOZ1dDKS7R9D7BQI\n7gGzV0Hzju6OSKlyNMkrpeoka8BdQd0dcBe3ED662ZoYZtYX1kIpStUxmuSVUnXSko2H6NCiKZf3\nqIPJc/2L8MXd1u1xMz625jZXqg7SJK+UqnMSUrL57/5UpvyuU90acGcMfPMYrJlvTXAzebHeT67q\nNL2FTilV58T+chhPD+GGujTgrqQYVv4Z4hfCgDkw7vn6O2e7ajQ0ySul6pSCohI+iktkRO82tG1W\nRwbcFRXAp7fCjk/gsnthxN90mldVLzjdXS8irUTkUxHJFpFDIjKtknItRORdETlhe8x3UOYuEfnN\nVtcuEenpbHxKqfrlqx3HSc2uQwPuCnJg6TQrwY96AkY+pgle1RuuaMm/ChQAbYFoYKWIbDHG7KhQ\n7kXADwgF2gDfisghY8xCABG5BbgZ+D2wC7gIOOWC+JRS9UjsxsN1Z8BdXjosmQyHf4arX4L+s9wd\nkVLnxamWvIj4AxOAR40xWcaY9cAKYKaD4lcDzxljcowxCcBbwBxbPR7AY8A9xpidxnLAGJPmTHxK\nqfrlt5RsfjyQytSBnfBw94C7rJPwzu8hMQ4mvq0JXtVLznbX9wSKjDF77bZtAcIqKS8Vnofbnne0\nPcJF5Iity/5xW/JXStVnJcVWl3c1xG48jJeHcMMANw+4O30EFo61FpyZuhTCx7s3HqUukLPd9QFA\nRoVt6UCgg7KrgQdF5Casrv05WN33YCV4gNFABNAC+BpIBP5VsSIRmQvMBejcuY5ct1NKOfb5XbAl\nFjpdDN2usNYnD4kEj/Ln8PlFxXwUn8jIPm1p484Bdyn7rKVi8zPhxs+g8yXui0UpJznbUs4CmlXY\n1gzIdFD2TiAX2AcsB2Kxkji27WB155+2dee/AYxzdFBjzJvGmAHGmAGtW9eB63ZKqcod/B5adoWC\nLFj7P/DmUPjfnvDJXNi6DLJTAPhqRzJp7h5wdzQe3h4LxfnWLHaa4FU952xLfi/gJSI9jDH7bNui\ngIqD7rBdX59e+lpE/g5stL3cgzV4z9i/xcnYlFLulpkM6UdgzN9h0B8h6wQcWAv7v4X9a2DrB4BA\nuyiKMnvz++YRXNZ1VM3HVVIMqQfg+FY4vu3MI/sENO8EMz/ThWZUg+BUkjfGZIvIJ8ATttHx0cC1\nwKUVy4pIN+C07TEaq7t9qK2eHBH5APiLiPwKNLft/4cz8Sml3OxovPWzQ3/rZ0AbiJpiPUpK4PgW\n2L+G3F1fc03mMsbLUnj+WbhoKHQbAd1HQAsnW/b5WZC8A5LtknnyTiiydSB6eEOb3tYUtW3DrZns\nAts6d0yl6ghX3EJ3O/A2cAJIBeYZY3aIyBBglTEmwFauP7AA63r7XmB6hdvs7gDeBI5hnQj8y1av\nUqq+OhoHHl6O11f38ID2/aB9P17I/D0fHdrB9xM9aJ74H6ulv+tzq1xwLyvZdx8BXQaDd1PHxzIG\nMpPKt8yPb4O0g5R1DPq2gJAIa8a6kAjrEdwTvJrUyMdXyt2cTvK2bvjrHGxfhzUwr/T1MmBZFfVk\nAFOcjUcpVYckxkHbsMoTM5BXaA24u6TvRTSP6Q8xE6yEnbLX6tLfvwZ+eQt+/id4+VqJvvtI6DgA\n0n6zutyTt1sJPSf1TMUtQ60kHjXlTEJv1kEnslGNik5rq5SqGSUlcOxXiJhUZbGvdhznVE5h+QF3\nItC6l/UY9EfrFrxDP1oJ/8C38NVfz5T19IE2faDXOGvUfkiEdWLhW3FMsFKNjyZ5pVTNSNkL+RlW\ni7sKizccpnMrPwZ3C668UBM/6DHSegCcOmS13IO6QVAP8NT/ypRyRP9lKKVqxtE462eHypP8/hNZ\nbPwtjQfG9j6/Ge5adrEeSqkq6YxySqmakRgHPs0hqPJb0UpnuJvYv2OlZZRSF06TvFKqZhyNhw4x\nZ81sVyqvsJiPNyUyJiyE1oE+tRycUo2DJnmllOsV5Fj3ppfeH+/A6u3HOV1xwJ1SyqU0ySulXC9p\nC5jiKgfdLdlwmC5Bfgy6KKgWA1OqcdEkr5RyvXMMutuXnMnGhDSmDuzs/iVllWrANMkrpVwvMc6a\njjbA8QJSSzYexttTB9wpVdM0ySulXO9ofKWt+LzCYj7ZdJTRYSEEB+iAO6VqkiZ5pZRrla48V8n1\n+C+3JZGeW8j0gTrgTqmapkleKeVa57gev2TDYboG+zOomw64U6qmaZJXSrlWYunKc5Fn7dqbnEnc\noVNMHdgJ0YVilKpxmuSVUq51NL7SleeWbDhME08PJsTogDulaoMmeaWU65SuPOegq94acJfImPAQ\ngnTAnVK1QpO8Usp1qlh57outSWTkFTFNB9wpVWs0ySulXKeKQXexGw9zUbA/l1zUqpaDUqrx0iSv\nlHKdSlae23M8k/hDp5g6sLMOuFOqFmmSV0q5ztE4hyvPLdlwyBpwpzPcKVWrNMkrpVyjIAeSd551\nPT63oJhPfj3K2PAQWvk3cVNwSjVOmuSVUq6RtNlaea7C9fgvth4jM69Il5RVyg00ySulXONovPXT\nbg359NxCFqzZR482AVzcVQfcKVXbvNwdgFKqgaiw8pwxhgc/3kpyRh4f3jZIB9wp5QbakldKuUaF\nlecWbzjMqu3HuX9ML/p1bunGwJRqvDTJK6WcV2HluV1JGTzxxU4u79maPwy5yM3BKdV4aZJXSjnP\nbhKcnIIi7liyieZNvXnhhig8PLSbXil30SSvlHKe3cpz81fs4GBKNgsmRxOsc9Qr5Vaa5JVSzjsa\nB23DWb4jjWVxifxxWHcGdw92d1RKNXqa5JVSzikphqO/khEcxUOfbGNAl5bcPbKHu6NSSqFJXinl\nrJR9UJDJvw+2wsvTg5em9sPLU/9rUaoucMm/RBFpJSKfiki2iBwSkWmVlGshIu+KyAnbY34l5YaK\niBGRJ10Rn1KqBtkG3a1Ma89zEyPp0KKpmwNSSpVy1WQ4rwIFQFsgGlgpIluMMTsqlHsR8ANCgTbA\ntyJyyBizsLSAiHgDLwEbXBSbUqoGJW5fRzPjx+WXDGJMWIi7w1FK2XG6JS8i/sAE4FFjTJYxZj2w\nApjpoPjVwHPGmBxjTALwFjCnQpk/A18Du52NTSlVs5LSc8k68DP7vXvxwLi+7g5HKVWBK7rrewJF\nxpi9dtu2AGGVlJcKz8PLXoh0wUr6T7ggLqVUDSouMdwf+zPdzWG6Rl+Or7enu0NSSlXgiiQfAGRU\n2JYOBDoouxp4UEQCRaQ7VkL3s9v/MrYegaoOKCJzRSROROJOnjzpROhKqQv18rf7yD+0CS8poWWP\nS90djlLKAVck+SygWYVtzYBMB2XvBHKBfcByIBZIBBCRq4FAY8wH5zqgMeZNY8wAY8yA1q1bOxO7\nUuoC/HQglVfW7mNmJ9tJdoXYv+A6AAAgAElEQVQ15JVSdYMrBt7tBbxEpIcxZp9tWxRQcdAdxpg0\nYHrpaxH5O7DR9nIEMEBEjtteNweKRSTCGHOtC+JUSrlAalY+d3/wK6FB/oxrdRQKuoC/TnyjVF3k\ndEveGJMNfAI8ISL+IjIYuBZYVLGsiHQTkSAR8RSRK4G5QOltco9iXd+Ptj1WAP8CZjsbo1LKNYwx\n3PfhFk5lF/LKtH54HdukrXil6jBXzVhxO9AUOIHVBT/PGLNDRIaIiP319f7ANqyu/KeB6aW32Rlj\nMo0xx0sfWN362bbWv1KqDnhr/W98t+ckD/++D2GBuZCRCB36uzsspVQlXHKfvC0RX+dg+zqsgXml\nr5cBy6pZ5yxXxKaUco2tiad5dvVuRvdty42DusCeL60dHbQlr1RdpXNPKqXOKTOvkDuW/ErrAB+e\nmxiJiJRbeU4pVTe5asY7pVQDZYzhoU+3c/R0Lh/MvYQWfk2sHbaV5/DWaWyVqqu0Ja+UqtKyuCN8\nvuUY947qyYDQVtZG28pzOuhOqbpNk7xSqlL7kjN5bMUOBncP4rah3c7sSNkLBZl6PV6pOk6TvFLK\nobzCYu5Y8isBPl68ODkaTw+7GakTrZXntCWvVN2m1+SVUg498cVO9iRn8u6cgbQJ9C2/82gc+DaH\nVt0cv1kpVSdoS14pdZaVW5NYsuEwtw69iKE9HUwdfTQe2seAh/4XolRdpv9ClVLl5BeV8OAnW4nu\n1IL7Rvc6u0BBDiTv1K56peoBTfJKqTLGwL4T1tpSr0zth7eng/8ikjaDKdZBd0rVA3pNXilV5sip\nHLLyivjfCZF0auXnuJAOulOq3tCWvFIKgD3HM0lKz6VNM1/GRbSrvODROGihK88pVR9okldKAfDi\nN3vxFKFzZS34Uonx2opXqp7QJK+UYvvRdFbvOE5I86Z42d8PX1HmcdvKc5rklaoPNMkrpXjxm700\nb+pNu+a+VRfU6/FK1Sua5JVq5DYdPsW3u08w9/KLys9q58jReGvluZCI2glOKeUUTfJKNXIvfrOX\nIP8mzLo09NyFdeU5peoVTfJKNWIbf0tj3b4UbhvaDX+fc9xRqyvPKVXvaJJXqpEyxvC/X++hdaAP\nMy7pcu436MpzStU7muSVaqR+PJDKht/S+OOwbjRt4nnuN+igO6XqHU3ySjVCpa34ds19mTKwc/Xe\npCvPKVXv6LS2SjVC3+89yabDp3nq+nB8vavRigdrEpwO/XXluRpQWFhIYmIieXl57g5F1TG+vr50\n7NgRb2/vC3q/JnmlGhljDC9+s5eOLZsyqX+n6r2pIBtO7IBe99VscI1UYmIigYGBhIaGInKO2xhV\no2GMITU1lcTERLp27XpBdegpuVKNzDc7k9mamM6dI3rQxKua/wUc2wymxGrJK5fLy8sjKChIE7wq\nR0QICgpyqodHk7xSjUhJieGFb/bSNdif8f06VP+NR+OtnzrorsZogleOOPt3oUleqUZk1fbj7D6e\nyV0jeuDlaK34yujKcw1aamoq0dHRREdHExISQocOHcpeFxQUVKuO2bNns2fPnirLvPrqqyxevNgV\nIQOQnJyMl5cX//73v11WZ0Oj1+SVaiSKSwwvrtlLjzYBXB3V/vzenBgPnS+umcCU2wUFBbF582YA\n5s+fT0BAAPfdV378hTEGYwwelQy8XLhw4TmP88c//tH5YO0sW7aMQYMGERsbyy233OLSuu0VFRXh\n5VU/06W25JVqJD7fcoz9J7K4e2TPc89Rb09Xnmu09u/fT9++fZk+fTphYWEkJSUxd+5cBgwYQFhY\nGE888URZ2csuu4zNmzdTVFREixYtePDBB4mKimLQoEGcOHECgEceeYQFCxaUlX/wwQcZOHAgvXr1\n4scffwQgOzubCRMm0LdvXyZOnMiAAQPKTkAqio2NZcGCBRw8eJCkpKSy7StXriQmJoaoqChGjx4N\nQGZmJjfddBORkZFERkby2WeflcVaaunSpWUnCzNmzGDevHkMHDiQhx56iJ9//plBgwbRr18/Bg8e\nzL59+wDrBOCee+4hPDycyMhI/vnPf/L1118zceLEsnpXrVrFpEmTnP59XIj6eWqilDovRcUlvPTt\nPnqHBHJleMj5vVknwalVj3++g53HMlxaZ9/2zXjs6rALeu/u3bt57733GDDA+v0/88wztGrViqKi\nIoYPH87EiRPp27dvufekp6czdOhQnnnmGe69917efvttHnzwwbPqNsawceNGVqxYwRNPPMHq1at5\n5ZVXCAkJ4eOPP2bLli3ExMQ4jCshIYG0tDT69+/PpEmTWLZsGXfddRfHjx9n3rx5rFu3ji5dupCW\nlgZYPRStW7dm69atGGM4ffr0OT97UlISP//8Mx4eHqSnp7Nu3Tq8vLxYvXo1jzzyCB988AGvvfYa\nx44dY8uWLXh6epKWlkaLFi244447SE1NJSgoiIULFzJnzpzz/epdQlvySjUCn/x6lN9Ssrl3VE88\nzqcVD9b1eA9vCImsmeBUndatW7eyBA9W6zkmJoaYmBh27drFzp07z3pP06ZNufLKKwHo378/CQkJ\nDuseP378WWXWr1/PlClTAIiKiiIszPHJydKlS5k8eTIAU6ZMITY2FoCffvqJ4cOH06WLNVVzq1at\nAFizZk3Z5QIRoWXLluf87JMmTSq7PHH69GkmTJhAeHg49913Hzt27Cir97bbbsPT07PseB4eHkyf\nPp0lS5aQlpZGfHx8WY9CbXO6JS8irYC3gNFACvBXY8wSB+VaAC8BV9o2/dMYM9+2r41t31DAH9gO\n3GuM2eBsfEo1dgVFJby0Zh+RHZszqm/b868gMQ5CwsH7HGvNK5e40BZ3TfH39y97vm/fPl566SU2\nbtxIixYtmDFjhsPbu5o0aVL23NPTk6KiIod1+/j4nLNMZWJjY0lJSeHdd98F4NixYxw8ePC86vDw\n8MAYU/a64mex/+wPP/wwY8aM4fbbb2f//v2MHTu2yrrnzJnDhAkTAJg8eXLZSUBtc0VL/lWgAGgL\nTAdeExFHf6UvAn5AKDAQmCkis237AoBfgP5AK+BdYKWIBLggPqUatWVxRzh6Opd7R/U8/9txSorh\n2K96f7wCICMjg8DAQJo1a0ZSUhJfffWVy48xePBgli1bBsC2bdsc9hTs3LmToqIijh49SkJCAgkJ\nCdx///0sXbqUSy+9lO+++45Dhw4BlHXXjxo1ildffRWwLhOcOnUKDw8PWrZsyb59+ygpKeHTTz+t\nNK709HQ6dLBuO33nnXfKto8aNYrXX3+d4uLicsfr1KkTwcHBPPPMM8yaNcu5L8UJTiV5EfEHJgCP\nGmOyjDHrgRXATAfFrwaeM8bkGGMSsFr/cwCMMQeNMS8YY5KMMcXGmDeBJkAvZ+JTqrHLKyzm/9bu\np3+Xlgzt2fr8K0jZCwVZOuhOARATE0Pfvn3p3bs3N954I4MHD3b5Mf70pz9x9OhR+vbty+OPP07f\nvn1p3rx5uTKxsbFcf/315bZNmDCB2NhY2rZty2uvvca1115LVFQU06dPB+Cxxx4jOTmZ8PBwoqOj\nWbduHQDPPvssY8aM4dJLL6Vjx46VxvXAAw9w//33ExMTU671f+uttxISEkJkZCRRUVFlJygA06ZN\no2vXrvTs2dPp7+VCiX2w5/1mkX7Af40xfnbb7gOGGmOurlA2BRhnjNloe/0wcJ8x5qwLIyISDfwM\ntDXGpFcVw4ABA0xcXNwFfwalGrKF//2Nxz/fyZJbLubS7ue+x332aqtzbeFY2+1QmxbBijvgjjgI\n7lGToTZqu3btok+fPu4Oo04oKiqiqKgIX19f9u3bx+jRo9m3b1+9vIXttttuY9CgQdx0001O1ePo\n70NE4o0x5zz7dvZbCwAqDgNNBwIdlF0NPCgiN2F17c/B6r4vR0SaAYuAxytL8CIyF5gL0LlzNVfQ\nUqqRyS0o5tXvDnDJRa2qleAd0pXnVC3LyspixIgRFBUVYYzhjTfeqJcJPjo6mpYtW/Lyyy+7NQ5n\nv7ksoFmFbc2ATAdl7wReAfYBqUAsMNW+gIg0BT4HfjbGPF3ZQW3d+W+C1ZK/0OCVasgW/ZxASlY+\nr81wfAtStejKc6qWtWjRgvj4eHeH4bTK7u2vbc7+y90LeImIfT9eFLCjYkFjTJoxZroxJsQYE2Y7\n9sbS/SLiA3wGJAK3OhmXUg1b1knY8Zk1MM7R7vwiXv/PQYb0COZ3oa0u7BilK8/p9Xil6i2nWvLG\nmGwR+QR4QkRuAaKBa4FLK5YVkW7AadtjNFZ3+1DbPm/gIyAXuMkYU+JMXEo1WMbAtg9h1QOQmwa9\nxsH4f4FP+RtR3v0xgbTsAv482omxq6Urz+kkOErVW67og7sdaAqcwOqCn2eM2SEiQ0Qky65cf2Ab\nVlf+08B0Y0xpi/9S4Cqs5H9aRLJsjyEuiE+phiH9KCyZDJ/8AYK6w7CHYO9qeHsMnD5SViwjr5A3\nfzjIiN5tiO7UoooKz+GobUCr3j6nVL3l9GgGY0wacJ2D7euwBuaVvl4GLKtYzrbvP4Cus6iUI8ZA\n/Dvwzd+gpAjGPA0X3woentCxP3w4G/51BUyNhY4DeGvdb6TnFnLPKCdv20mMg5ahuvKcUvWYjqZR\nqi5LOwjvXg1f3A3to2HejzDodivBA3QfCTd/A038YOE4suM/4O31vzE2LITwDs2rrvtcjm7SVnwj\nMXz48LMmtlmwYAHz5s2r8n0BAVY77tixY+UWZLE3bNgwznWb84IFC8jJySl7PW7cuGrNLV9d0dHR\nZVPlNjaa5JWqi0qK4adX4Z+XQtIWuPoluHEFtOp6dtk2veGWtdChP/6fz+WW4qXcM9LJe9p15blG\nZerUqSxdurTctqVLlzJ16tRK3lFe+/bt+eijjy74+BWT/JdfflludThn7Nq1i+LiYtatW0d2drZL\n6nTkfKflrS2a5JWqa07usa6zf/UQdL0cbv8Z+s+Cqqak9Q8idfwHfGqGcpfXJ/RafycU5l54DLry\nXKMyceJEVq5cSUFBAWCt8Hbs2DGGDBlSdt96TEwMERERLF++/Kz3JyQkEB4eDkBubi5TpkyhT58+\nXH/99eTmnvk7nDdvXtkytY899hgAL7/8MseOHWP48OEMHz4cgNDQUFJSUgB44YUXCA8PJzw8vGyZ\n2oSEBPr06cMf/vAHwsLCGD16dLnj2IuNjWXmzJmMHj26XOz79+9n5MiRREVFERMTw4EDBwBrBryI\niAiioqLKVs6z741ISUkhNDQUsKa3veaaa7jiiisYMWJEld/Ve++9VzYr3syZM8nMzKRr164UFhYC\n1pTB9q9dpf7NMKBUQ1VcCP9dAP95DpoEWKPmIyZVndztvP7fRN4qmMvlwy4j6Ke/w6lD1nX6wPNc\nWhZ05Tl3WvUgHN/m2jpDIuDKZyrd3apVKwYOHMiqVau49tprWbp0KTfccAMigq+vL59++inNmjUj\nJSWFSy65hGuuuabSdRBee+01/Pz82LVrF1u3bi23VOxTTz1Fq1atKC4uZsSIEWzdupU777yTF154\nge+++47g4PLjP+Lj41m4cCEbNmzAGMPFF1/M0KFDy+abj42N5V//+hc33HADH3/8MTNmzDgrng8+\n+IBvvvmG3bt388orrzBt2jQApk+fzoMPPsj1119PXl4eJSUlrFq1iuXLl7Nhwwb8/PzK5qGvyqZN\nm9i6dWvZ8ruOvqudO3fy5JNP8uOPPxIcHExaWhqBgYEMGzaMlStXct1117F06VLGjx+Pt7f3OY95\nPrQlr1RdkLQF/jUc1j4JvX8Pf9wIkTdUO8EnZ+Tx3k+HuK5fR4LG/AUmvw8nd1sD8pK2nH88uvJc\no2PfZW/fVW+M4aGHHiIyMpKRI0dy9OhRkpOTK63nhx9+KEu2kZGRREaeOVFctmwZMTEx9OvXjx07\ndjhcfMbe+vXruf766/H39ycgIIDx48eXzTnftWtXoqOjgcqXs42LiyM4OJjOnTszYsQIfv31V9LS\n0sjMzOTo0aNl89/7+vri5+fHmjVrmD17Nn5+1mSspcvUVmXUqFFl5Sr7rtauXcukSZPKTmJKy99y\nyy0sXGhNIb1w4UJmz57t+CBO0Ja8Uu5UmAc/PAfrF1ij2Ccvhj5XnXc1//xuP0UlhrtG2K7F97kK\n5nwFsVPg7bFWr0C16zXWynNR1bseq1ysihZ3Tbr22mu555572LRpEzk5OfTvbw26XLx4MSdPniQ+\nPh5vb29CQ0MdLi97Lr/99hvPP/88v/zyCy1btmTWrFkXVE+p0mVqwVqq1lF3fWxsLLt37y7rXs/I\nyODjjz8+70F4Xl5elJRY07dUtRzt+X5XgwcPJiEhge+//57i4uKySx6upC15pdzlyEZ4Ywis+1+I\nmgJ/3HBBCf7o6VxiNx5hUv+OdAk68x8O7SLhD2uhTR/4YAasf9G6He9cCnKtlef0enyjEhAQwPDh\nw5kzZ065AXfp6em0adMGb2/vcku4Vubyyy9nyZIlAGzfvp2tW7cCVoL19/enefPmJCcns2rVqrL3\nBAYGkpl59mzoQ4YM4bPPPiMnJ4fs7Gw+/fRThgyp3vQpJSUlLFu2jG3btpUtR7t8+XJiY2MJDAyk\nY8eOfPbZZwDk5+eTk5PDqFGjWLhwYdkgwNLu+tDQ0LKpdqsaYFjZd3XFFVfw4YcfkpqaWq5egBtv\nvJFp06bVSCseNMkrVfsKsq3rrm+NtgbHzfgYrvsnND1rQcZq+b+1+zEY7rii+9k7A0Ng1koIux7W\nzIfPboei/HPEZ/vPVkfWNzpTp05ly5Yt5ZL89OnTiYuLIyIigvfee4/evXtXWce8efPIysqiT58+\n/O1vfyvrEYiKiqJfv3707t2badOmlVumdu7cuYwdO7Zs4F2pmJgYZs2axcCBA7n44ou55ZZb6Nev\nX7U+y7p16+jQoQPt27cv23b55Zezc+dOkpKSWLRoES+//DKRkZFceumlHD9+nLFjx3LNNdcwYMAA\noqOjef755wG47777eO211+jXr1/ZgEBHKvuuwsLCePjhhxk6dChRUVHce++95d5z6tSpat/JcL6c\nWmq2LtClZlVdYIwht7CY9NxC65Fj/czIKyI9txC/Jp70DgmkT+4mfFfdA6cPwe/+ACMfAx9HizZW\nz+HUHK743++ZOrAz/3NdFV19xsD3z8B/noHOg6xr9g4muZm9ejak7mfhkUPwlwRdmKaW6FKzjddH\nH33E8uXLWbRoUaVl3LnUrFINSl5hMSlZ+WXJOqPsZ9GZBG73yMgtJCPPel5YXPkJcyA5/NVrMf28\nvuOItGdZhxfx8hlCn/3Z9GnnSYcWTfHwOP9JH19euw8PD+GPwx204u2JwPC/WmvCf3a7NSBv2gdW\nV35F+Zm68pxSteBPf/oTq1at4ssvv6yxY2iSV/XT6cOw/eNKV2G7EKdyCnl/wyFyCxzX6SHQxtuT\nzl4e+Hp74uPtia+PBz4Bnvh6e+Jr2+7r7YGPl902zxK8Ni/CMzuZuA4zec9nGttOFJDw7d6yS+QB\nPl70CgmkT7tAeoc0o0+7QHqFNCPAp/J/ogdPZvHJpkRmXdqVkObVHAUfMdGaqjZ2qnW5YOJC6DHy\nzH5TDIU5EKpd9UrVtFdeeaXGj6FJXtU/h360BpLlpLq02pbAnwCquk3VAIW2x/loGw7TFjOgQ39K\n02d2fhF7kzPZfTyT3UkZ7ErKZPnmY7yfd7jsbZ1aNaVPSDN6t2tGn5BAerdrRpdWfnh4CC99uw8f\nL0/mDet2frF0HGANyIudCksmwdhnYOBcq7Wfn2V17eugO6UaBE3yqn7ZvARW3Aktu8Ds1Var1AW2\nJp5mwus/cfuwbtwz0smFXRzx9D7rnnd/Hy/6dW5Jv85nBtwZYziWnsfupAx2H89kZ1IGu5MyWLMr\nmRJbq7+ptyc9QwLZmniaWy/vRutAH85bi04wZ7W1ot2qv1iz7F35rNVVDzpnvVINhCZ5VT+UlMC3\nj1szwnUdCje8e8Gj0SsyxvD3rw8Q6O/HLcN6gZdrZ5w6HyJChxZN6dCiKSP6tC3bnldYzL7kLHYd\nz2BXUga7kzKJ7NCcWy+/6MIP5hNgDcBbMx9+fBnSDoA5bU2AoyvPKdUgaJJXdV9+Fnx6K+z+AgbM\ngSufs1rGLvL9npP8fDCNx68JI9DXfQm+Kr7enkR0bE5ERydXlqvIwxNG/w+07gWf3w1tWoJ/a9ce\nQynlNjp8VtVt6YmwcCzs+RLGPgu/f8GlCb64xPDMqt2EBvkxdWBnl9Vb7/SbATcuBy9f8A9ydzTK\nDZ566inCwsKIjIwkOjqaDRs2AGevEFdd77zzDseOHXO4b9asWWXT0kZHR/Pyyy8DrlliduHChWX1\nNmnShIiICKKjo8sWmzlfDz/8MN99951TMbmTtuRV3ZUYD0unQkEOTFsGPUa5/BAfb0pkT3Imr06L\noYlXIz/nDR2sA+4aqZ9++okvvviCTZs24ePjQ0pKStmKdAsWLGDGjBll87lXR3FxMe+88w7h4eHl\nJqOx949//OOsNehdcSvZ7Nmzy2aPCw0Ndbjwzfl46qmnnI7JnRr5/2qqztr+MbwzDrx84JZvaiTB\n5xYU88LXe4nq1IJxERewUptSDURSUhLBwcFl88EHBwfTvn17h8vAOlouFqyE+sADDxATE0NsbCxx\ncXFMnz6d6OjoSpeBrah0idmqlpI9cOAAY8eOpX///gwZMoTdu3dX+3M+8sgjZcvVAvTu3ZvExET2\n799PeHg4N998M2FhYVx55ZVlc87PmDGjbPrbjh07Mn/+fPr160dkZCR79+4F4MSJE4wYMYKwsDBu\nvfVWOnTo4HSPhKtoS17VLcZYS61+/3fodAlMWVxjg8De/u9vHM/I46Up0ZUum6lUbXt247PsTqt+\n4qqO3q1688DAByrdP3r0aJ544gl69uzJyJEjmTx5MkOHDnW4DKyj5WJLV5oLCgpi06ZNAPz73//m\n+eefZ8AAx71D999/P08++SQAixYtIiIiotz+ypaSnTt3Lq+//jo9evRgw4YN3H777axdu9bp72jP\nnj3ExsYSERHB+PHj+eyzzxwuZNO2bVt+/fVXXn75ZV544QVef/11/va3vzF27Fjuv/9+vvjiC958\n802n43EVTfKq7ijMheV3wPaPrBXQrn7JasnXgLTsAl7//gAj+7Th4ov0GrRq3AICAoiPj2fdunV8\n9913TJ48mWeeeYZZs2adVXbZsmW8+eabFBUVkZSUxM6dO8uS/OTJk6t9TEfd9fYcLSWblZXFjz/+\nyKRJk8rK5eefYy2GaurevXvZiUZlS9cCjB8/vqxM6eWF9evX8/DDDwNw1VVXERh44VNVu5omeVU3\nZCbD0mlwNA5GPAaX3VPttdQvxCtr95FdUMQDY6tebEOp2lZVi7smeXp6MmzYMIYNG0ZERATvvvvu\nWUn+XMvF2i+76ixHS8mWlJTQokULNm/efEF12i8ZC+WXja14vKKioirjqqpMXaLX5JX7Hd9mzaV+\nYqd13/aQe2s0wR9OzeH9nw9xw4BO9Ghbd864lXKXPXv2sG/fvrLXmzdvpkuXLkD5ZWCrWi62osqW\nj3VGs2bN6Nq1Kx9++CFgzXGxZcuWar/ffsnYjRs3cuTIEZfENXjwYJYtWwZYgwdd/bmdoUleudfu\nL+GtMWBKrBnY+lxd44f8x9d78PQQ7hlVAzPbKVUPZWVlcdNNN9G3b18iIyPZuXMn8+fPB8ovA1vV\ncrEVzZo1i9tuu+28Bt5Vx+LFi3nrrbeIiooiLCyM5cuXV/u9kyZNIjk5mfDwcN58800uusiJyaTs\nPP7446xcuZLw8HBWrFhBmzZtXNqr4Qxdala5hzHWLGvfPAbto2FKLDRrV+OH3Zp4mmv+77/cMbw7\n943pVePHq29mr7ZuPVo4dqGbI2lcdKnZ+i0vLw8vLy+8vLxYv349d999N67MS7rUrKpfigrgi3tg\n8/vQ9zq47jVoUv17cC+UMYanv9xNK/8m3DrUNWfwSimVkJDA1KlTKS4uxsfHhzfeeMPdIZXRJK9q\nV3YqLJsJh/4Ll/8Fhv211tYt/37vSX46mFqnp69VStU/vXv35tdff3V3GA5pkle15+QeWHIDZCTB\n+H9D5KRzv8dFiksMz3y5my6NffpapVSjokle1Y7938KHs8GrCcz6AjoNrNXD6/S1qq4zxuikTOos\nzo6b0//tVM2LWwiLJ0HzjvCHtbWe4PMKdfpaVbf5+vqSmprq9H/oqmExxpCamoqvr+8F16EteVWz\ntn0EX9wNPUbDxLfBp/bvSy+dvnaBTl+r6qiOHTuSmJjIyZMn3R2KqmN8fX3p2LHjBb/fJUleRFoB\nbwGjgRTgr8aYJQ7KtQBeAq60bfqnMWa+3f5QYCFwMXAYuMMYs8YVMSo3OPg9fHobdLkMblgE3hd+\nNnqh0rILeO07a/raS3T6WlVHeXt707VrV3eHoRogV3XXvwoUAG2B6cBrIhLmoNyLgB8QCgwEZorI\nbLv9scCvQBDwMPCRiLR2UYyqNiVthaUzILiHtciMGxI8wP+t3a/T1yqlGi2nk7yI+AMTgEeNMVnG\nmPXACmCmg+JXA88ZY3KMMQlYrf85tnp6AjHAY8aYXGPMx8A2W92qPjl1CBZPBN9mMP0jaNrCLWEc\nScth0c8JOn2tUqrRckVLvidQZIzZa7dtC+CoJQ8gFZ6H256HAQeNMfaT/lZVj6qLctLg/QlQlAcz\nPobmHdwWyj++0ulrlVKNmyuuyQcAGRW2pQOOmk6rgQdF5Casrv05WN33pfWkO6jnrCwhInOBubaX\nWSKy58JCdygYa1xBQ1P7n+uvfWv6CNX6TCFP1nQYLuf2v8F3eMfVVbr9M9WAhviZoGF+rob4mbpU\np5ArknwW0KzCtmaAo2V47gReAfYBqVjX4Keebz3GmDeBNy885MqJSFx15gOubxri52qInwka5ufS\nz1R/NMTP1RA/U3W5oufvOzkAACAASURBVLt+L+AlIj3stkUBOyoWNMakGWOmG2NCjDFhtuNvtO3e\nAVwkIoHnqkcppZRS5+Z0kjfGZAOfAE+IiL+IDAauBRZVLCsi3UQkSEQ8ReRKrC73J2317AU2A4+J\niK+IXA9EAh87G6NSSinVGLnqFrrbgabACawu+HnGmB0iMkREsuzK9ccaMZ8JPA1MN8bYt9SnAAOA\nU8AzwERjTG3PDlEjlwHqgIb4uRriZ4KG+bn0M9UfDfFzNcTPVC31fj15pZRSSjmmc9crpZRSDZQm\neaWUUqqBapRJXkRaicinIpItIodEZFol5UREnhWRVNvjWamDK5yIiI+IvGX7LJkistk2sNFR2Vki\nUiwiWXaPYbUccrWJyPcikmcXq8M5EerR7yqrwqNYRF6ppGyd/V2JyB0iEici+SLy/+zdeXxU5fX4\n8c/JQgJZ2EKCSVhlSUggAQIuiLK4gIIo4A4CSrFg61K18rVardXWtmqt/qxKi6iIqFUQFXFDFHAB\nwr6DsgaQVZaENcn5/XEnYRgmyWSdSXLer9e8krn3ufeeOzdw5j73WV7zWNdXRNaJyFERmSMiRfbn\nFZGWrjJHXdtcWunBF6Oo8xKR80XkCxE5ICJ7ReR/InJOMfvx6e+2KhRzTi1FRD3+vh4pZj8Bc62K\nOadbPM7nqOscuxaxn4C5TpWlViZ5fB9rfwxwDU5Xvk44w/LeUVVBlkIIsB24BKgPPAy8K86EP958\nr6qRbq+vqyTKsvuNW6ztiyhTLa6V++cONAWOAf8rZpNAvVY7cXrGvOq+UERicHrbPAI0AjKBd4rZ\nT6DNV+H1vICGOI23WuIMQnIEZzKt4vjyd1sVijqnAg3c4vxzMfsJpGvl9ZxUdYrHv7FxwCZgSTH7\nCpTrVClqXZKX0o21PwJ4RlWzVHUH8AwwssqC9ZGq5qjqY6q6RVXzVfVjYDNOb4baolpcKw9DcHqk\nzPN3IKWlqtNU9QOcQa3cDQZWq+r/VPU48BiQJiJnzRAkAThfRVHnpaqzXOd0WFWPAv8P6OGXIEup\nmGvls0C7VqU4pxHAG1qLW5jXuiRP6cbaT3GtK6lcQBGROJzzLGogoc4isk9ENojIIyJSIVMOV6K/\nuuL9tpjq6up4rXz5D6i6XaszroNrHI2fKPrfV3Wdr+JiSh6oy5e/20CwVUSyRGSSqybGm2p3rVyP\niS4G3iihaHW5TmVSG5N8acba9xxP/xAQGYjPeguISCgwBXhdVdd5KTIXZ1KgWJxv4TcBD1RdhKX2\nINAaZw6DCcBHInKul3LV6lq5/gO6BHi9mGLV7VpB0XNQ+PLvq7iyAUNEOgF/pPhr4evfrT/tA7rh\nPH7oivO5TymibHW8VrcC81R1czFlqsN1KpfamORLM9a+Z9loIDtQq35EJAhnpMGTwG+8lVHVTaq6\n2VWtvxJ4HBhahWGWiqouUNUjqnpCVV8HvgWu9FK0Wl0rnMdD84v7D6i6XSuX8vz7Kq5sQBCRNsAs\n4G5VLfIxSyn+bv3G9bgyU1VzVXU3zv8Zl8uZQ4sXqHbXCifJF/clulpcp/KqjUne57H2XcvSfCjn\nd6471ok4jQmHqOopHzdVzpz+N9AVFW+1uVYuJf4H5EV1uFZnXAdXG5hzKfrfV7WZr8JV+/Il8GdV\nPWvY7hJUh2tX8IXYW16obteqBxAPvFfKTavDdSqVWpfkSzPWPs6znN+JSIKIxAP3QcXPwVlBXgKS\ngYGqeqyoQiLS3/XMHldjqEeAGVUTYumISAMRuUKcuQxCROQWnGdsn3opXm2ulYhciFM9WFyr+oC+\nVq7rEQ4EA8EF1wiYDqSKyBDX+j8CK7w9OgrE+SqKOi8RSQC+Av6fqr5cwj5K83db6Yo5p/NEpL2I\nBIlIY+B54GtV9ayWD7hrVczfX4ERwPsebQg89xFQ16nSqGqte+F07fkAyAG2ATe7lvfEqeItKCfA\n34EDrtffcQ0FHEgvnGdqChzHqVYreN0CNHf93txV9mlgt+vcN+FUAYf6+xyKOK8mwCKcKsGDwA/A\nZdX5WrlifQWY7GV5tblWOK3m1eP1mGvdpcA6nO6BXwMt3bZ7GXjZ7X1LV5ljwHrg0kA8L+BR1+/u\n/77c//4eAmaV9HcbYOd0E04vnBxgF84X5abV4VqV8PcX7vrc+3rZLmCvU2W9bOx6Y4wxpoaqddX1\nxhhjTG1hSd4YY4ypoSzJG2OMMTWUJXljjDGmhrIkb4wxxtRQluSNKQMRCXZNTdm8Isv6k4i0EZFK\n6W7juW8R+dzVL7nC43CN8V9sX3ZjagtL8qZWkDPnmM4XkWNu770mm+Koap46U1Nuq8iygUpEvhSR\nP3pZPkREdohIcGn2p6qXq2pR46SXJq5LRWSLx77/rKq/Lu++vRxrtIh8XdH7NaYyWZI3tYKeOcf0\nNpyRAQuWnZVsqsFsb1XtdbxPxzwceFNV86o4HmOMDyzJGwOIyBMi8o6ITBWRI8AwEblARH4QkYMi\nsktEnnfN8lcwrKaKSEvX+zdd62eJyBER+V5EWpW2rGt9f3Gmlj0kIi+IMwXmyCLi9iXGO0TkRxH5\nRUSed9s2WET+KSL7RWQT0K+Yj2ga0NQ1JG/B9o1xJvN4w/X+ahFZJiKHRWSbiDxSzOc9v+CcSorD\ndQe91vVZ/SQio13L6wMfAc3damViXdfyNbftrxWR1a7P6CsRae+2LktEficiK12f91QRCSvmcyjq\nfBJF5GMROSAiG0XkNrd154vIEtfnsltE/uFaXk9E3nKd90ERWShFT/VqTJlYkjfmtGuBt4D6wDtA\nLnA3EAP0wEk+dxSz/c0448s3wqkt+HNpy4pILPAuzjSmMTjDjnYvZj++xHglzlSinXG+vFzqWj4W\nuBxnopFuwPVFHUSdOR/ew5lYp8CNOOPSF0xSUjCUcgNgIHC3iAwoJvYCJcWxG7gKZ9azXwEviEgn\ndcZYHwhsc6uV2eO+oYgk48xL8VucYUy/BD4s+CLkcj1wGc6Uo13xXmNRkndwrlU8cAPwdxG5xLXu\nBeAfqhoNtOH0pCmjgHpAItAYGIczNLUxFcaSvDGnzVfVj9SZ2vWYqi5SZyrKXFXdhDPf9CXFbP+e\nOlN3nsKZlzu9DGUHAMtUdYZr3T9x5v32yscY/6qqh1R1C87Y4wXHuh74p6pmqep+4Kli4gWnyv56\ntzvdM2bSU9WvVHW16/NbDrztJRZvio3DdU02qeMrYDbO3AW+uBH40BXbKde+6wPnuZV5TlV/dh37\nY4q/bmdx1cJ0B8ar6nFVXQJM4vSXhVNAWxFprM60pgvclscAbVztNjJVNbs0xzamJJbkjTltu/sb\nEUkSkZki8rOIHMaZIKa46tSf3X4/CkSWoWy8exzqTC6RVdROfIzRp2MBW4uJF+Ab4DAwUETa4dQM\nTHWL5QIR+VpE9orIIWC0l1i8KTYOERkgIgtcVeEHce76fa3Wjnffn6rm43yeCW5lSnPdijrGPldt\nR4GtbscYBXQA1ruq5AvmK38Np2bhXXEaLz4l1hbEVDBL8sac5tlt6xVgFc6dVjTOtKmVPdf0Lpzq\nWwBERDgzIXkqT4y7gGZu74vt4uf6wvEGzh38cOATVXWvZXgbZ+rRZqpaH/ivj7EUGYeI1MWp3v4r\nEKeqDYDP3fZbUle7nTizNBbsLwjn893hQ1y+2gnEiEiE27LmBcdQ1fWqeiMQCzwDvC8i4ap6UlUf\nU9Vk4CKcx0Wl7ulhTHEsyRtTtCjgEJDjerZb3PP4ivIx0EVEBrru6u7GeZZcGTG+C9wjIgmuRnQP\n+rDNGzjP/W/DrareLZYDqnpcRM7HqSovbxxhQB1gL5Dnesbf1239bpwEG1XMvq8WkV6u5/AP4Ewt\nuqCI8iUJEmf+8cKXqm4GMoG/iEiYiKTj3L2/CSAiw0UkxlWLcAjni0m+iPQRkVTXF4/DONX3+WWM\nyxivLMkbU7T7gBE4SeEVnMZVlUpVd+M03HoW2A+cCywFTlRCjC/hPN9eiTOv9nvFFwdV/RFYiJN8\nZ3qsHgv8VZzeCQ/hJNhyxaGqB4F7genAAWAozhehgvWrcGoPtrhaqMd6xLsa5/N5CeeLQj/gatfz\n+bLoiTOfuvsLnGvWFqfq/z3gIVX92rXuSmCt63N5GrhBVU/iVPNPw0nwq3Gq7t8qY1zGeGXzyRsT\nwMQZZGYnMFRV5/k7HmNM9WJ38sYEGBHpJyINXK3YH8Gpxl3o57CMMdWQT0leRBqJyHQRyRGRrSJy\ncxHlHhCRVa5BKzaLyAMe61uKyBwROSoi69z66xasv7eglbCIvFqWQSmMqQEuAjbhVC9fAVyrqkVV\n1xtjTJF8vZN/ETgJxOG0/nxJRFK8lBOclrcNcZ59/UZE3BvfTMV5vtgY+APwnog0ARCRK4DxOI1q\nWuAMTPGn0p6QMdWdqj6sqo1UNVpVL1DVRf6OyRhTPZX4TN7VLeQXIFVVN7iWTQZ2qOr4ErZ93nWM\n37r61a4EYlT1iGv9PGCKqr4sIm8BW1T1Ide6vq51Tct3isYYY0zt5MudfDsgtyDBuywHvN3JF3L1\n7+2J02oUV/lNBQney35SXO/d18W5utQYY4wxppR8GV0pEqeLh7tDOH1ii/MYzpeISW77OeRlPwlF\nrC/4PQqnK1EhERkDjAGIiIjompSUVEIoxhhfbDm8BYCW0S2dBXvXkS8hrD7RhKbR4TSJsmYyxgSC\nxYsX71PV4sbQAHxL8tk4E0O4i8bpl+uViPwG59l8T7cGQyXtx3N9we9nHUdVJ+CM0U1GRoZmZmaW\nfBbGmBKN+nQUAJP6ub6bf3QPrJrGdfUn8cvxPL6492KcSjpjjD+JSEnDUAO+VddvAEJEpK3bsjRO\nV8N7Hvg2XA3oVNV9zO3VQGuPkanc97Pa9d593W7XpBHGGH9IzIAThxjRPpcf92SzcodnZZwxJpCV\nmORdky5MAx4XkQgR6QEMwpm+8QwicgvwF+Ay14xY7vvZACwDHnUNB3kt0AlntCpwhsu8XUQ6iEgD\n4GGcCRyMMf6S2A2APpHbqBMSxLQlFTnkuzGmsvnahW4cUBfYg9MNbqyqrhaRniLiPjXiEzjd4xaJ\nSLbr9bLb+huBDJzW+k/hjOK1F0BVPwX+DszBmV97K/Bo2U/NGFNujdtCWH3q7VnCZclxfLh8Jydz\nbXh1Y6oLn6Y1VNUDwDVels/DbVpGVW1Vwn62AL2KWf8szpjdxphAEBQECV0gK5PBvf6PmSt38c2G\nvVzWIc7fkRng1KlTZGVlcfz4cX+HYipJeHg4iYmJhIaGlml7m7vYGFO8xG4w72kublmPxhF1mLYk\ny5J8gMjKyiIqKoqWLVtag8gaSFXZv38/WVlZtGpV7D10kWzsemNM8RIzQPMJ3b2cq9Pjmb12DweP\nnvR3VAY4fvw4jRs3tgRfQ4kIjRs3LldNjSV5Y0zxEjKcn1mZDOmSyMm8fD5escu/MZlCluBrtvJe\nX0vyxpjiRTSGRq0haxEp8dG0i4tk2pKskrczNd7+/ftJT08nPT2dpk2bkpCQUPj+5EnfantGjRrF\n+vXriy3z4osvMmXKlIoImYsuuohly5ZVyL6qA3smb4wpWUIGbJ6LAIO7JPLUrHVs3pdDq5gIf0dm\n/Khx48aFCfOxxx4jMjKS+++//4wyqoqqEhTk/Z5y0qRJXpe7u/POO8sfbC1ld/LGmJIldoPsn+Hw\nDq5JT0AEptvdvCnCjz/+SIcOHbjllltISUlh165djBkzhoyMDFJSUnj88ccLyxbcWefm5tKgQQPG\njx9PWloaF1xwAXv27AHg4Ycf5rnnnissP378eLp370779u357rvvAMjJyWHIkCF06NCBoUOHkpGR\n4fMd+7FjxxgxYgQdO3akS5cuzJ07F4CVK1fSrVs30tPT6dSpE5s2beLIkSP079+ftLQ0UlNTee+9\n9yryo6twluSNMSVL7Or8zFpE0/rhXNQmhmlLd5CfX/wslqb2WrduHffeey9r1qwhISGBp556iszM\nTJYvX84XX3zBmjVrztrm0KFDXHLJJSxfvpwLLriAV1991eu+VZWFCxfyj3/8o/ALwwsvvEDTpk1Z\ns2YNjzzyCEuXLvU51ueff56wsDBWrlzJ5MmTGT58OCdPnuTf//43999/P8uWLWPRokXEx8fzySef\n0LJlS5YvX86qVau47LLLyvYBVRGrrjfGlCyuIwSHQVYmpFzL4C4J3PvOchZtOcB5rW2iyEDwp49W\ns2an51xi5dMhPppHBxY74WiRzj33XDIyMgrfT506lYkTJ5Kbm8vOnTtZs2YNHTp0OGObunXr0r9/\nfwC6du3KvHnzvO578ODBhWW2bNkCwPz583nwwQcBSEtLIyXF97jnz5/PAw88AEBKSgrx8fH8+OOP\nXHjhhTzxxBNs3bqVwYMH06ZNGzp16sT48eMZP348AwcOpEePHj4fxx/sTt4YU7KQOhCf7iR54IqU\nptSrE2zD3JoiRUScbq+xceNG/vWvf/HVV1+xYsUK+vXr57VbWJ06dQp/Dw4OJjc31+u+w8LCSixT\nEYYPH8706dMJCwujX79+zJ07l+TkZDIzM0lJSWH8+PH85S9/qbTjVwS7kzfG+CYhAzInQt4p6tUJ\npX/qOcxcuYs/DUohPDTY39HVemW9464Khw8fJioqiujoaHbt2sVnn31Gv379KvQYPXr04N1336Vn\nz56sXLnS6+OAovTs2ZMpU6Zw8cUXs3btWnbt2kWbNm3YtGkTbdq04e6772bz5s2sWLGCc889l5iY\nGIYPH05UVBRvvvlmhZ5HRbMkb4zxTWIG/PAi7F4F8Z0Z0iWB95dk8fma3VydFu/v6EwA69KlCx06\ndCApKYkWLVpUShX3b3/7W2699VY6dOhQ+Kpfv77XsldccUXhMLE9e/bk1Vdf5Y477qBjx46Ehoby\nxhtvUKdOHd566y2mTp1KaGgo8fHxPPbYY3z33XeMHz+eoKAg6tSpw8svv+z1GIFCVKt3wxmbT96Y\ninPWfPLuDm6H51Lhyqeh+6/Iz1cu+ttXtGsaxWujuldxpAZg7dq1JCcn+zuMgJCbm0tubi7h4eFs\n3LiRyy+/nI0bNxISUv3vZb1dZxFZrKoZRWxSqPqfvTGmatRPhMg457l8918RFCRc0zmBl7/5iT1H\njhMbFe7vCE0tlp2dTd++fcnNzUVVeeWVV2pEgi8v+wSMMb4RcfrLZy0qXDS4SwL//vonPly2k9E9\nW/sxOFPbNWjQgMWLF/s7jIBjreuNMb5L6AoHfoKjBwBoExtFWmJ93rdW9sYEJJ+SvIg0EpHpIpIj\nIltF5OYiyvUWkTkickhEtnisay4i2R4vFZH7XOt7iUi+x/oR5T5DY0zFSezm/Nxx+o5pcJdE1u46\nXOF9tI0x5efrnfyLwEkgDrgFeElEvPXXyAFeBR7wXKGq21Q1suAFdATygffdiu10L6Oqr5fmZIwx\nlSy+M0jQGVX2A9PiCQkSpi+1YW6NCTQlJnkRiQCGAI+oaraqzgc+BIZ7llXVhao6Gdjkw7FvBeaq\n6pbShWyM8ZuwSIjtUDgoDkCjiDr0Torlg2U7yc3L92NwxhhPvtzJtwNyVXWD27LlQJlHXhBngtxb\nAc879VgR2S0im0Xkn64vGMaYQJKYATsyIf90Qh/SJYG9R04w/8d9fgzMVLXevXvz2WefnbHsueee\nY+zYscVuFxkZCcDOnTsZOnSo1zK9evWipO7Rzz33HEePHi18f+WVV3Lw4EFfQi/WY489xtNPP13u\n/QQCX5J8JOD5sO0QEFWO416EU/XvPn3POiAdOAfoA3QFnvW2sYiMEZFMEcncu3dvOcIwxpRaQgYc\nPwT7fyxc1Dsplvp1Q22Y21rmpptu4u233z5j2dtvv81NN93k0/bx8fHlmsXNM8l/8sknNGjQoMz7\nq4l8SfLZQLTHsmjgSDmOOwJ4X1WzCxao6s+qukZV81V1M/B7nMcEZ1HVCaqaoaoZTZo0KUcYxphS\nK2x8d/ouKywkmIFp5/DZ6p85cvyUnwIzVW3o0KHMnDmTkydPArBlyxZ27txJz549C/utd+nShY4d\nOzJjxoyztt+yZQupqamAM93rjTfeSHJyMtdeey3Hjh0rLDd27NjCaWofffRRwJk5bufOnfTu3Zve\nvXsD0LJlS/btc2qTnn32WVJTU0lNTS2cpnbLli0kJyfzq1/9ipSUFC6//PIzjlMSb/vMycnhqquu\nKpx69p133gFg/PjxdOjQgU6dOnH//feX6nOtSL70k98AhIhIW1Xd6FqWBqwuywFFpC5wHXBtCUUV\n6+JnTOCJaQdh0U7ju/TTHW0Gd0nkzR+2MWvlz1zfrZkfAzRVpVGjRnTv3p1Zs2YxaNAg3n77ba6/\n/npEhPDwcKZPn050dDT79u3j/PPP5+qrr8Z5Wnu2l156iXr16rF27VpWrFhBly5dCtc9+eSTNGrU\niLy8PPr27cuKFSu46667ePbZZ5kzZw4xMTFn7Gvx4sVMmjSJBQsWoKqcd955XHLJJTRs2JCNGzcy\ndepU/vOf/3D99dfz/vvvM2zYsBLPtah9btq0ifj4eGbOnAk40+Xu37+f6dOns27dOkSkQh4hlFWJ\nSV5Vc0RkGvC4iIzGqVIfBFzoWVZEgoA6QKjzVsKBfFU96VbsWuAXYI7Htr1xGuxtAxKBp4Czv/oZ\nY/wrKAgSupzR+A6gc7MGtIqJ4P0lWZbk/WHWePh5ZcXus2lH6P9UsUUKquwLkvzEiRMBZ873hx56\niLlz5xIUFMSOHTvYvXs3TZs29bqfuXPnctdddwHQqVMnOnXqVLju3XffZcKECeTm5rJr1y7WrFlz\nxnpP8+fP59prry2cCW/w4MHMmzePq6++mlatWpGeng6cOVVtSYraZ79+/bjvvvt48MEHGTBgAD17\n9iwcXvf2229nwIABDBgwwKdjVAZf75THAXWBPcBUYKyqrhaRniKS7VbuYuAY8AnQ3PX75x77GgFM\n1rMHze8MfIfTDe87YCVwVynOxRhTVRK7we7VcDKncJGIMLhzAgs2H2D7gaPFbGxqkkGDBjF79myW\nLFnC0aNH6dq1KwBTpkxh7969LF68mGXLlhEXF+d1etmSbN68maeffprZs2ezYsUKrrrqqjLtp0DB\nNLVQMVPVtmvXjiVLltCxY0cefvhhHn/8cUJCQli4cCFDhw7l448/rvAZ90rDp2FtVfUAcI2X5fNw\nGuYVvP8a8F4Xc7rMFUUsf5YiGtoZYwJMQgZoHuxcBi1Pzyh2TecEnvliAx8s3cFv+7b1Y4C1UAl3\n3JUlMjKS3r17c9ttt53R4O7QoUPExsYSGhrKnDlz2Lp1a7H7ufjii3nrrbfo06cPq1atYsWKFYAz\nTW1ERAT169dn9+7dzJo1i169egEQFRXFkSNHzqqu79mzJyNHjmT8+PGoKtOnT2fy5MnlOs+i9rlz\n504aNWrEsGHDaNCgAf/973/Jzs7m6NGjXHnllfTo0YPWrf035LONXW+MKb1E1+RXOzLPSPLNGtXj\nvFaNmLZ0B7/p06bI56+mZrnpppu49tprz2hpf8sttzBw4EA6duxIRkYGSUlJxe5j7NixjBo1iuTk\nZJKTkwtrBNLS0ujcuTNJSUk0a9bsjGlqx4wZQ79+/YiPj2fOnNNPgLt06cLIkSPp3t2ZHXH06NF0\n7tzZ56p5gCeeeKKwcR1AVlaW131+9tlnPPDAAwQFBREaGspLL73EkSNHGDRoEMePH0dVefZZ/92/\n2lSzxphCxU416+lf6dA0FW5484zF7y7azu/fX8G0cRfSpXnDygjTuNhUs7VDeaaatdbrxpiyScyA\nrLNn/erfsSlhIUFMW2LD3Brjb5bkjTFlk9gNjuyEQ2cOgBMVHsoVKU35aPkuTuTm+Sk4YwxYkjfG\nlFXBc3m3yWoKDO6SwKFjp5izbk8VB2WMcWdJ3hhTNnEdITjsjJHvClzUJoYmUWE2z7wxfmZJ3hhT\nNiF14Jy0swbFAQgJDuKa9HjmrNvDgZyTXjY2xlQFS/LGmLJLzHD6yuedPV794C6J5OYrHy3f6YfA\njDFgSd4YUx6JGZB7zBn9zkPyOdEknxNtrexruCeffJKUlBQ6depEeno6CxYsAM6eIc5Xr732Gjt3\nev9iOHLkyMJhadPT03n++eeBiplidtKkSYX7rVOnDh07diQ9PZ3x48eXaX9/+MMfzui77y82GI4x\npuwKZqTLWgTx6WetHtIlgSdmruXHPUdoE1ue2alNIPr+++/5+OOPWbJkCWFhYezbt69wRrrnnnuO\nYcOGUa9ePZ/3l5eXx2uvvUZqairx8fFey/zjH/84aw76Tz75pOwn4TJq1ChGjXLGiWjZsqXXiW9K\n48knnyx3TBXB7uSNMWVXvxlExMKOs/vLA1ydHk+QYPPM11C7du0iJiamcDz4mJgY4uPjvU4D6226\nWHAS6oMPPkiXLl2YOnUqmZmZ3HLLLaSnp/s8DWzBFLPFTSX7008/0a9fP7p27UrPnj1Zt26dz+f5\n8MMPnzH6XVJSEllZWfz444+kpqZy++23k5KSQv/+/QvH1R82bBgffPABAImJiTz22GN07tyZTp06\nsWHDBgD27NlD3759SUlJ4Y477iAhIaHCZ6yzJG+MKTsR527eSzc6gNiocHq2bcKHy3dS3UfXNGe7\n/PLL2b59O+3atWPcuHF88803ANx1112FQ80WVFk/+eSTZGZmsmLFCr755pvCsekBGjduzJIlSxg2\nbBgZGRlMmTKFZcuWUbdu3bOO+cADDxRWq69cefasexs3buTOO+9k9erVNGjQgPfffx9whsB94YUX\nWLx4MU8//TTjxo2rkM9g/fr13HPPPaxevZq6desWJnZPcXFxLF26lNGjRxcOc/vHP/6Rfv36sXr1\nagYOHFjkY4rysOp6Y0z5JHaF9TPh6AGo1+is1VekNOWh6SvZuCebdnFWZV9Z/rbwb6w74PvdqS+S\nGiXxYPcHi1wffhtT5wAAIABJREFUGRnJ4sWLmTdvHnPmzOGGG27gqaeeYuTIkWeVLW662BtuuMHn\nmLxV17vzNpVsdnY23333Hdddd11huRMnTvh8zOK0adOGjh07nnE8bwYPHlxYpuDxwvz58/nDH/4A\nwIABA4iKqvh/H5bkjTHlU/BcfscSaHvpWav7JMUC8OXa3Zbka6Dg4GB69epFr1696NixI6+//vpZ\nSb5guthFixbRsGFDRo4cecZ0sQVztFcEz6lkjx07Rn5+Pg0aNGDZsmVl2mdISAj5+fmF791j93Xq\n2oJyFTG9bWlYkjfGlE98Z5Agp8reS5JvWj+c1IRovlq7h3G92vghwNqhuDvuyrJ+/XqCgoJo29aZ\nVnjZsmW0aNECOHMa2OKmi/VUsF1Fio6OplWrVvzvf//juuuuQ1VZsWIFaWlpPm3fsmVLvvjiCwAW\nLlzI9u3bKySuHj168O6773LffffxySefVPh5g4/P5EWkkYhMF5EcEdkqIjcXUa63iMwRkUMissXL\n+i0ickxEsl2vzz3W3ysiP4vIYRF5VUTCPPdhjAkwYVHQJNnryHcF+iTFsWTbLzYwTg2TnZ3NiBEj\n6NChA506dWLNmjU89thjwOlpYHv37n3GdLE333zzGdPFeho5ciS//vWvS9XwzhdTpkxh4sSJpKWl\nkZKSwowZM3ze9rrrrmP37t2kpqYyYcKECpsf/k9/+hMzZ84kNTWVDz/8kNjY2Aqt1QAfp5oVkak4\nXwhuB9KBmcCFqrrao1x3oD1QF3hIVVt6rN8CjFbVL70c4wrgDaAPsBOYDvygqsV2UrSpZo2pOKWa\natbdh3fBmhnw+80QdPa9w/LtBxn04rf884Y0ru2cWBGhGmyq2eru+PHjhISEEBISwvz587nnnnvw\nls8qdapZEYkAhgCPqGq2qs4HPgSGe5ZV1YWqOhnYVNJ+vRgBTFTV1ar6C/BnYGQZ9mOMqWqJGXD8\nIBz4yevqjgn1aRIVxpdrbcIaYwps2bKFbt260alTJ+69915eeeWVCj+GL8/k2wG5qrrBbdly4JIy\nHnOKiAQBS4EHVHW5a3kK4F5/shyIE5HGqrq/jMcyxlSFwkFxMiGm7Vmrg4KEPu1j+WTlLk7l5RMa\nbL13jUlKSmLp0qWVegxf/qVFAoc9lh0CytJM9hagJdACmAN8JiIN3I5zyOMYeDuOiIwRkUwRydy7\nd28ZwjDGVKiY9hAWXWR/eYA+ybEcOZHLoi0HqjAwY2o3X5J8NhDtsSwaKHUzQFX9VlWPqepRVf0r\ncBDoWcRxCn4/6ziqOkFVM1Q1o0mTJqUNwxhT0YKCnFb2xTS+u6hNDHWCg5htVfYVygYZqtnKe319\nSfIbgBARca+DSwPOnpGi9BQQ1++rXft1P8Zuq6o3pppI7AY/r4KT3icliQgL4fxzG/PVOkvyFSU8\nPJz9+/dboq+hVJX9+/cTHh5e5n2U+ExeVXNEZBrwuIiMxmldPwi40LOs61l7HSDUeSvhQL6qnhSR\n5kAzYBHOl4vfAjHAt67N3wBeE5EpOK3rHwZeK/OZGWOqVmI30DzYtQxanPXfAwCXJsfyxxmr2bQ3\nm9ZNIqs4wJonMTGRrKws7LFlzRUeHk5iYtl7pPg6GM444FVgD7AfGKuqq0WkJzBLVQv+tV6M86y9\nwDHgG6AXzrP1l4BzgePAMqB/wZ26qn4qIn93bV8XeB94FGNM9ZDo6s2TlVlkku/dPhZYzVfr9liS\nrwChoaG0atXK32GYAOZTklfVA8A1XpbPw2kwV/D+a05Xv3uWXQ10KuE4zwLP+hKTMSbARMRAw5bF\nNr5r1qge7eOi+HLtbkb3rJgBRYwxRbN+LMaYipOQUeS0swX6JseyaMsvHDp2qoqCMqb2siRvjKk4\nid3g8A44VPT88X2TY8nLV+ZusOfIxlQ2S/LGmIpTOCNd0V3p0ps1pGG9UGtlb0wVsCRvjKk4TVMh\nuI7T+K4IwUFC7/axzFm/h9y8/CLLGWPKz5K8MabihITBOWnFJnmAvslxHDx6iqXbD1ZRYMbUTpbk\njTEVKyEDdi6FvNwii/RsF0NIkNjod8ZUMkvyxpiKlZgBucdgT9GDYkaHh9K9VSO+Wre7CgMzpvax\nJG+MqViFM9IV3V8eoE9SLBt2Z7P9gPdhcI0x5WdJ3hhTsRo0h4gmkFV8f/lLk+MAmL3W7uaNqSyW\n5I0xFUvEuZsv4U6+ZUwErZtEMNu60hlTaSzJG2MqXkJX2L8Rjv1SbLG+SbEs2HSA7BNFN9IzxpSd\nJXljTMUrHBSn+Cr7PklxnMzLZ/5GG/3OmMpgSd4YU/ESugBSYn/5jJYNiQ4Psa50pmZT9duhLckb\nYypeWBTEJpeY5EODg7jENfpdfr7//iM0ptJs+RYmXwM5+/1yeEvyxpjKkZjhjGFfwl1M36RY9mWf\nZHmWjX5napiD2+DdW50Jm4J9mtm9wvmU5EWkkYhMF5EcEdkqIjcXUa63iMwRkUMissVjXayITBWR\nna7134rIeW7re4lIvohku71GlOvsjDH+k9jNaXh3YFOxxS5p14QgwSasMTXLyRx4+2bIOwU3TYXw\n+n4Jw9c7+ReBk0AccAvwkoikeCmXA7wKPOBlXSSwCOgKNAJeB2aKSKRbmZ2qGun2et3H+IwxgSYh\nw/lZQle6hhF1yGjRyJ7Lm5pDFWbcCT+vgqETIaat30IpMcmLSAQwBHhEVbNVdT7wITDcs6yqLlTV\nycBZX91VdZOqPququ1Q1T1UnAHWA9uU+C2NM4GnSHupElZjkAfokx7Jm12F2HTpWBYEZU8nmPwur\np8Olj0Hby/waii938u2AXFXd4LZsOeDtTt5nIpKOk+R/dFscKyK7RWSziPzT9QXD27ZjRCRTRDL3\n7rWuN8YEpKBgSOhcYuM7cJ7LA3Y3b6q/9Z/C7D9Dx+ugx93+jsanJB8JHPZYdgiIKutBRSQamAz8\nSVUPuRavA9KBc4A+ONX6z3rbXlUnqGqGqmY0adKkrGEYYypbYjfYvQpOFX+H3iY2kmaN6tpzeVO9\n7V0P74+GczrB1S84oz/6mS9JPhuI9lgWDRwpywFFpC7wEfCDqv61YLmq/qyqa1Q1X1U3A7/HeUxg\njKmuErtBfi7sWl5sMRGhb1Ic3/64j2Mn86ooOGMq0LFfYOpNEBoON74FoXX9HRHgW5LfAISIiHvL\ngTSg6HkkiyAiYcAHQBZwRwnF1cf4jDGBysfGdwB9k2M5kZvPdz/tq+SgjKlg+Xnw3u1Ol7nrJ0P9\nRH9HVKjEjnuqmiMi04DHRWQ0TpX6IOBCz7IiEoTznD3UeSvhQL6qnhSRUOA94BgwQlXzPbbtjdNg\nbxuQCDwFzCjPyRlj/CyyCTRoAWtmOF2IQsIhJMz1M/yM990bhNKyziG+XfkjfdtEQ3AYBNn3fFMN\nfPkY/DQbBv4LWlzg72jO4Gvv/HE4XeP2APuBsaq6WkR6ArNUtaAb3MXAHLftjgHfAL1wvhQMcC07\nKKefVfRX1XlAZ+BNoKHrGNOBP5TttIwxAaNNX8h8tcS7+TDg6yBgjesFEFzH44uB2xeE8GhodQkk\nXeXXLkqmllvxLnz3PHQbDV1H+juas4j6cUzdipCRkaGZmSW33jXGlGzUp6MAmNRvUsXtVBVy9kHe\nCcg94TTCyz0BucddrxOFPxf/tJOPl2zmjgsTaBohZ64/5VH+yM+wx/XUsHFbSLoS2l/ljLQXFFxx\n8RtTlB1LYFJ/57HUrR9AcGiVHVpEFqtqRknl/DPOnjGm9hBxqu190PzcE7yW+SUNw9txVy8f7s4P\nbof1s2D9TPj+Rfj2XxDRBNr1c+7wW/cKmAZQpoY5shvevgUiYuH616s0wZeGJXljTMBoEhVGWmID\nZq/dzV19fUjyDZrBeWOc17GDsPELJ+Gv/gCWTobQenBuH2h/pZP4IxpX/kmYmi/3BLw7HI4fhNs+\ng4gYf0dUJEvyxpiAcmlyLE9/voE9R44TGxXu+4Z1G0Cn65xX7gnYMg/WfeLc6a/7GCQImp3v3OEn\nXQmNWlfeSZiaSxVm3gfbF8B1rzl94gOYNV01xgSUPklxAHy9rhyjWYaEQZtLYcCz8Ls18Ks50PM+\nOH4IPv8DPN8ZXjwfZj8OWYshP7/kfRoDsOi/Ti3RxQ9AyrX+jqZEdidvjAkoyedEcU79cGav2831\n3ZqVf4cikNDFefV5GA5sdj3H/wTmPwfznoHIptC+/+nn+AH6fNX42eZ5MOtBaNcfej3k72h8Ykne\nGBNQRIQ+SbFMX7qD46fyCA+t4JbyjVrBBeOc19EDsOEz5zn+indh8SRo2hGunQBxHSr2uKZ6+2WL\nMzd84zYweEK1GcOhekRpjKlVLk2O4+jJPBZsPlC5B6rXCNJvghvehN9vgiET4fAumHAJfPeCM5KZ\nMSeynZb0mueaG95zpPfAZUneGBNwLji3MeGhQXy1dnfVHTQ0HDoOhXE/QJvL4POH4fWB8MvWqovB\nBB5V+GAs7FkDQydB43P9HVGpWJI3xgSc8NBgLmoTw5dr91DlA3ZFNoEbp8Cgf8OuFfBSD1gy2fnP\n3tQ+c5+GtR/CZX92Rm+sZizJG2MCUp+kOHYcPMaG3dlVf3AR6HwLjPsO4tPhw9/A2zdDtk2FW6us\nmwlznoBON8IFd/o7mjKxJG+MCUh9kmIBmL2uCqvsPTVoDrd+CJc/CT/Ohn9fAGs/9l88pursWQvT\nxkB8Fxj4XEDMDV8WluSNMQGpaf1wUhOi+Wqtn++eg4Lgwt/AHd9AdDy8cwtMH+v0uTc109EDztzw\ndSKcRzfVeGhkS/LGmIDVJymOJdt+4UDOSX+HArHJMHq2MwjKiredZ/Wb5/k7KlPR8nLhvdvg8A6n\n10V0vL8jKhdL8saYgNU3KZZ8ha/XB8iz8JA6zoA6t33uTIP7+gD49CFnhjxTM3z5KGyaAwP+Cc26\n+zuacvMpyYtIIxGZLiI5IrJVRG4uolxvEZkjIodEZIuX9S1d64+KyDoRudRj/b0i8rOIHBaRV0Uk\nrExnZYypETom1KdJVBiz1wVIki/QrBv8ep4zh/gPLzr96ncu83dUZXfsF6cHwZTrYerNMO9Z2DIf\nTub4O7Kqk58HC16B7/8fnPdr6DzM3xFVCF9HvHsROAnEAenATBFZrqqrPcrlAK8CUwFvY/5NBb4H\nrnS93hORtqq6V0SuAMYDfYCdwHTgT65lxphaKChI6NM+lk9W7uJUXj6hwQFU+VgnAq56xhkOd8Zv\n4L994ZLxcNG9EFwNBhM9ccQZ3nfV+06jwvxT0KAFBIU4IwACSDDEpTh3tIndnFej1tW2EZpXxw85\nX3AWvgIHt0Hr3nD5E/6OqsKU+JcoIhHAECBVVbOB+SLyITAcjwSsqguBhZ536K79tAO6AJer6jHg\nfRG5x7Xvl4ERwMSCLw4i8mdgiucxjDG1S5/kWN7J3M6izQe4sE0ATunZ5lIY9z3MvN/pbrXhU7j2\nFYhp4+/IznbqmDOM76r3YePnkHscohPgvDsgdbDTklwEcvbDjkzYvhCyFsHyt52JWQDqNT6d8Jt1\nd7YJi/TveZXFgU3OnfvSN+FkNjS/EK74izMtcVAFD6XsR7583WwH5KrqBrdly4FLSnmsFGCTqh7x\n2E+K2/oZHuviRKSxqu4v5bGMMTXERW1iqBMcxOx1ewIzyQPUbQhDJzpT2H78O3j5Irj8z051vr/v\nenNPwE9fOYl9/SwnoUU0gc7DIXUINDvv7HHYIxpDuyucFzhV2XvXnU76WYucLzPgTOEbmwKJGa47\n/u7OqHD+Pm9vVGHrt/DDS04f+KBg5zM4fyzEd/Z3dJXClyQfCRz2WHYIiCrlsSJd23nuJ6GI9QW/\nRwFnJHkRGQOMAWjevHkpwzDGVCcRYSFccG5jvlq3h0cGBPikMalDnDvCGXfCJ/c7M90NerHqW2jn\n5cLmb2DVNFj3kVMlXbehE1/qYGhxUekeKQS5qu3jUiBjlLPs6AHYsdhJ+NsXOl8iFk9y1tVt6Lrb\n7+4k/4Su/h3vPfeE81n88G/4eQXUbeRMPdxtNESf47+4qoAvVzkb8Lw60cARL2XLsx/P9QW/n3Uc\nVZ0ATADIyMiwsSaNqeH6Jsfyxxmr2bQ3m9ZNArxqOPocGPY+ZL7qjH//7/OdbneNWkNErDNsbkQs\n1KlXscfNz4Nt3zvJds2HcHQf1ImC5AGQMtiZQjekTsUdr14jaHuZ8wLIz4d968+829/4ubNOgiAu\nFZpfAM3Pd35WRXLN2edch0X/hezd0CQJBv4LOt1Qrfu+l4YvSX4DEOJqILfRtSwN8Gx0V5LVQGsR\niXKrsk8D3nJbnwa867Zut1XVG2N6t48FVjN77Z7AT/LgVFV3u91JrNN/7SR7T3WiTif8wp+uV8Hv\nEU2cn3UivB9HFbIyXYn9AziyC0LqOo0BUwc7E+2EhlfmmZ4WFOSMJRCbDF1HOMuOHXTu9rcvgG0/\nwFJXAzdwGvm1uPB00o9pV3FV/LvXOHftK96FvBPO53D+WDi3T2A+RqhEJSZ5Vc0RkWnA4yIyGqd1\n/SDgQs+yIhIE1AFCnbcSDuSr6klV3SAiy4BHReRhoD/QCafhHcAbwGsiMgWndf3DwGvlPUFjTPXX\nrFE92sdFMXvdbn51cWt/h+O7xufC7Z87A6tk74Gcva6feyB7r+vnHti30emyduwX7/sJjTj7i0BQ\nqPOM/dA2p89+28sh5Vpo1y9wGsLVbeBM6lIwsUveKfh5pZPwt30HP34Jy6e6yjY6nfCbXwDnpJWu\n5iE/39nfDy/Cpq+dLzvpNzvJvUn7Cj+16sLXhzLjcLrG7cF5Pj5WVVeLSE9glqoW/EVdDMxx2+4Y\n8A3Qy/X+RpzE/QuwDRiqqnsBVPVTEfm7a/u6wPvAo2U7LWNMTdM3OZZX5m7i0LFT1K8b6u9wfCcC\n9ROdV0nyTrl9EXD/QrDn9O/7f3Kq5U8cgVYXQ+//g6SrILx+5Z9LeQWHQkIX53XBOKcm4sAm53y2\nfu/8XP+JUzYkHBIyTif+Zt29P9c/meN8UfjhZdi/EaLioe+j0HWk80ihlpMqn8axgmVkZGhmZqa/\nwzCmRhj1qdOoalK/SX6O5GyLtx5gyEvf88JNnRmYVr2HGq0QqjWz6jl7j+tO/wcn6e9aDprneq6f\ncvq5fkw7WPkeLH4Njh90uvJdcCd0GOR8majhRGSxqmaUVK4ajNhgjDGQ3qwhjSLqMHvtbkvyUDMT\nPDiPIjpc7bwATmQ7ffYLkv7SKbBwgrNOgiB5IJx/p3OnX1M/k3KwJG+MqRaCg4Re7Zvw1bo95Obl\nExJIo9+ZyhMW6TRgbN3LeZ+XC7tXws+rnMcVDVv4L7ZqwP6VGGOqjb5JcRw8eoql2w/6OxTjL8Eh\nzsA1XYZbgveBJXljTLXRs10MIUHCbH/PMW9MNWFJ3hhTbUSHh9K9VSNmr93t71CMqRYsyRtjqpW+\nyXFs3JPNtv1H/R2KMQHPkrwxplrpmxQLwFfr7G7emJJYkjfGVCstYyJo3SSC2evsubwxJbEkb4yp\ndvomxfLDpv0cOnbK36EYE9AsyRtjqp2r0xLIy1cemraS6j5qpzGVyZK8Maba6ZhYn9/3S2Lmyl28\nMneTv8MxJmBZkjfGVEt3XNyaqzqew98/Xce8jXv9HY4xAcmSvDGmWhIR/j60E21jo/jt1KVsP2Bd\n6ozxZEneGFNtRYSF8MrwruTnK2MmL+bYyTx/h2RMQLEkb4yp1lrGRPCvmzqz7ufDjJ+2whriGePG\npyQvIo1EZLqI5IjIVhG5uYhyIiJ/E5H9rtffRJy5/0Skp4hke7xURIa41o8UkTyP9b0q7EyNMTVW\n7/ax3H95e2Ys28nE+Zv9HY4xAcPXqWZfBE4CcUA6MFNElqvqao9yY4BrgDRAgS+AzcDLqjoPiCwo\n6ErgHwGfum3/vapeVIbzMMbUcuN6ncvKrEP8ddY6OpwTzYVtYvwdkjF+V+KdvIhEAEOAR1Q1W1Xn\nAx8Cw70UHwE8o6pZqroDeAYYWcSuRwDvqWpOmSI3xhg3IsLT16fRKiaC30xdStYv1hDPGF+q69sB\nuaq6wW3ZciDFS9kU17piy7m+OAwFXvdY1VlE9onIBhF5RER8rWkwxhgiw0KYMLwrp3Lz+fWbizl+\nyhrimdrNlyQfCRz2WHYIiCqi7CGPcpEFz+XdDAb2Ad+4LZsLpAKxODUHNwEPeAtIRMaISKaIZO7d\na/1jjTGntW4SyXM3prNqx2Eemm4j4pnazZcknw1EeyyLBo74UDYayNaz/5WNAN5wX66qm1R1s6rm\nq+pK4HGcu/2zqOoEVc1Q1YwmTZr4cArGmNqkb3Ic91zalmlLdvD6d1v8HY4xfuNLkt8AhIhIW7dl\naYBnoztcy9KKKycizYBewBslHFcBzxoAY4zxyV192nJpcix/nrmWHzbt93c4xvhFiUne1TBuGvC4\niESISA9gEDDZS/E3gN+JSIKIxAP3Aa95lBkOfKeqP7kvFJH+IhLn+j0JeASYUcrzMcYYAIKChGdv\nSKdFo3rcOWUJOw8e83dIxlQ5XwfDGQfUBfYAU4Gxqrq6oO+7W7lXcLrFrQRWATNdy9zdytkN7gD6\nAitEJAf4BOeLxV98PRFjjPEUHR7KhFu7cvxUHmOtIZ6phXxK8qp6QFWvUdUIVW2uqm+5ls9T1Ui3\ncqqqv1fVRq7X7z2fx6tqkqpO9HKM+1U1znWM1qr6R1W1yaKNMeXSJjaKZ65PZ3nWIf44Y5U1xDO1\nig1ra4yp8fqlNuW3fdrwbmYWUxZs83c4xlQZS/LGmFrhnkvb0bt9E/700WoytxzwdzjGVAlL8saY\nWiE4SHjuxs4kNKjL2ClL2H34uL9DMqbSWZI3xtQa9euG8srwDHJO5DL2zcWcyLWGeKZmsyRvjKlV\n2jeN4h9D01iy7SB/+miNv8MxplJZkjfG1DpXdTqHX19yLm8t2MbUhdYQz9RcluSNMbXSA1e0p2fb\nGB6dsZol237xdzjGVApL8saYWik4SHjhps7E1Q9j7JuL2XPEGuKZmseSvDGm1mpQrw6vDMvg0LFT\n3DllCSdz8/0dkjEVypK8MaZW6xAfzd+GdGLRll94YqY1xDM1S4i/AzDGGH8blJ7Aqh2H+M+8zQSJ\nMObi1sQ3qOvvsIwpN0vyxhgDPNgviV+OnuKN77cw+Yet9Ettym09WtGleQNEbNZrUz1ZkjfGGCAk\nOIinr0vjnkvb8sb3W5m6cBszV+wiLbE+t13Uiv6p51AnxJ5wmurF/mKNMcZNYsN6PHRlMj/8X18e\nH5TCkeO53P32Mnr+/StenPMjB3JO+jtEY3xmd/LGGONFRFgIt17QkmHnteCbDXt59dvN/OOz9Tw/\neyODuyQwqkcr2sVF+TtMY4rl0528iDQSkekikiMiW0Xk5iLKiYj8TUT2u15/E7eHWSKirn1ku17/\n9XVbY4zxh6AgoXdSLJNvP4/P7rmYwV0SmLZkB5f/cy7D/ruAr9btJj/f5qg3gcnXO/kXgZNAHJAO\nzBSR5aq62qPcGOAaIA1Q4AtgM/CyW5k0Vf3RyzF82dYYY/ymfdMo/jq4Ew9ckcTUhdt44/st3PZa\nJq1iIhjVoyVDuiQSEWYVpCZwlHgnLyIRwBDgEVXNVtX5wIfAcC/FRwDPqGqWqu4AngFG+hhLebY1\nxpgq0yiiDnf2bsP8B/vwrxvTiQ4P4Y8zVnP+X2fz5Mw1bD9w1N8hGgP4diffDshV1Q1uy5YDl3gp\nm+Ja514uxaPMXBEJAr4DfqeqW0qxLQAiMgbnzp/mzZv7cArGGFPxQoODGJSewNVp8SzZdpBXv93M\nq99uYeL8zVyR0pTbLmpFRouG1gXP+I0vST4SOOyx7BDgrcVJpGude7lIERFVVZwvBj8A9YAngI9F\nJF1Vc33YtpCqTgAmAGRkZNjDMGOMX4kIXVs0pGuLhuw8eKywC96sVT/TMaE+v+nThitSmvo7TFML\n+dLwLhuI9lgWDRzxoWw0kF2QpFV1rqqeVNWDwN1AKyDZl22NMaY6iG9Ql/H9k/j+//rwxDWp5JzM\n5Y7Ji/lf5nZ/h2ZqIV+S/AYgRETaui1LAzwb3eFaluZDuQIKFNRjlXZbY4wJWPXqhDDs/BbMursn\nPdvG8OD7K5i5Ype/wzK1TIlJXlVzgGnA4yISISI9gEHAZC/F3wB+JyIJIhIP3Ae8BiAiKSKSLiLB\nIhKJ07BuB7C2pG2NMaa6CgsJ5pXhXenSvCF3v72UOev2+DskU4v4OuLdOKAusAeYCoxV1dUi0lNE\nst3KvQJ8BKwEVgEzXcvA6X73Ds7z/U1AS2CAqp7yYVtjjKm26tUJ4dVR3Ug6J4pfv7mY73/a7++Q\nTC0h1f2Rd0ZGhmZmZvo7DGNqhFGfjgJgUr9Jfo6kZtqffYIbJvzAroPHeHP0eXRu3tDfIZlqSkQW\nq2pGSeVs7HpjjKkijSPDmDL6PBpHhjFy0iLW7vLsuGRMxbIkb4wxVSguOpwpo8+jbmgwwycuYNPe\n7JI3MqaMLMkbY0wVa9aoHm+OPg9VGPbfBWT9YiPkmcphSd4YY/ygTWwkb9zenSMncrnlvwvYc/i4\nv0MyNZAleWOM8ZOU+Pq8Nqo7e4+cYNjEBfxic9WbCmZJ3hhj/Khri4b859YMtuw/yohJCzly/FTJ\nGxnjI0vyxhjjZz3axPDvm7uwZudhbn8tk2Mn8/wdkqkhLMkbY0wAuLRDHM/ekM6irQe4483FnMi1\nRG/Kz5K8McYEiKvT4nlqcEfmbtjL3VOXkZuX7++QTDVnSd4YYwLIDd2a88iADny6+md+/94K8vOr\n96ikxr98mU/eGGNMFbr9olbknMjl2S82EBEWwuODUhCRkjc0xoMleWOMCUC/7dOG7BO5TJi7iYiw\nEB7s194SvSk1S/LGGBOARIT/659EzolcXv7mJyLDgvlNn7b+DstUM5bkjTEmQIkIfx6UytGTeTz9\nuVN1P6o6tA9HAAAPbklEQVRHK3+HZaoRnxreiUgjEZkuIjkislVEbi6inIjI30Rkv+v1N3HVL4lI\nOxGZISJ7ReSAiHwmIu3dth0pInkiku326lUhZ2mMMdVUUJDwj6GduLxDHH/6aA3vLtru75BMNeJr\n6/oXgZNAHHAL8JKIpHgpNwa4BkgDOgEDgTtc6xoAHwLtXftZCMzw2P57VY10e31dinMxxpgaKSQ4\niBdu7kzPtjGMn7aCj1fs9HdIppooMcmLSAQwBHhEVbNVdT5Osh7upfgI4BlVzVLVHcAzwEgAVV2o\nqhNV9YCqngL+CbQXkcYVdC7GGFNjhYUE88rwrnRt0ZB73l7GV+t2+zskUw34ciffDshV1Q1uy5YD\n3u7kU1zrSioHcDHws6rud1vWWUT2icgGEXlERKzNgDHGuNSrE8LEkd1IOieKX7+5hN+9s4xZK3eR\ncyLX36GZAOVLEo0EDnssOwREFVH2kEe5SBERVS0c0UFEEnEeAfzOrexcIBXYivPF4B0gF/ir50FE\nZAzOowGaN2/uwykYY0zNEB0eyhu3nff/27v34CrrO4/j708SEjAXEkjCHVPCJQQkUHFt8QKCuNrd\nVlt2p9M6W6yz0506znbWjnvr4q3dta3tTKfttsi0Be06zq4VL7RSQREvjLXFCyAh0DGAgpAIyC1c\nQnK++8fzJBzOnHNyAiTnku9r5hk4z/N7nvy++T4533Oey+/hwee2saaxhZVv76WwII+rJ1aysH4E\nC6ZWU106ON3ddBkilSJ/HCiLmVcGHEuhbRlwPKbAVwFrgJ+Z2eNd882sOWq9LZIeAO4mTpE3s2XA\nMoDZs2f7cFDOuQFlWHEhD/1tAw92RvjTro9Z07iftY0trGtqRYJZ48q5YdpIFtaPoLaqJN3ddWmU\nSpHfARRImmRmfw7nNQBb47TdGi77Y7x2kioICvyzZvafPfxcA3zkB+ecS6AgP49P1w7n07XDueev\n62naf4w1W1tYu20/313dxHdXNzGhqpgb6oOCP2tcOXl5/rY6kPRY5M2sTdJK4AFJfw/MBG4G5sRp\n/ihwl6TnCIr0N4GfAEgqA54HNpjZv8auKOkm4C0za5FUBywBnji/sJxzbmCRxNRRZUwdVcY3rp/E\n3sMneaGxhTWN+/nFq80sffk9KkuKWFhfzcL6EcyprWTwoPx0d9v1sVQvbLsD+BXQChwEvm5mWyVd\nA6w2s67jQQ8DE4At4etfhPMAPg9cAUyTdFvUtuvN7H1gAbBCUgnQAvwP8F/nFZVzzg1wY8qHsHhO\nDYvn1HDkxBnW72hlzdYWnn3nQx7/4wdcUpjP3MlVLKwfwfy6asovKUx3l10fUNTp8qw0e/Zs27hx\nY7q74VxO+OrvvwrA8huXp7knrq+c7ujk9fcOsqaxhRcaW2g9dpr8PPEXNcO4YdoIrp5YyYSqEvL9\nsH5Gk/Smmc3uqZ3fouaccwNIUUE+86ZUM29KNd+5eTqb9hxmbWMLaxtbuH9VIwDFhflMHzOUhnHl\nNIwtZ8bYoYytGOIPyMlCXuSdc26AyssTs8ZXMGt8Bf98Yx27DrTx5u6P2bTnMJv2HGHFhl20d0YA\nGF5cyIyxQ5kxtpyGccG/lSVFaY7A9cSLvHPOOQBqKoupqSxm0eVjAWjviNC0/yib9hxh8weH2bTn\nMOt3fETXWd4x5UNoGDc0/LZfzmVjh1JS5GUlk3g2nHPOxVVYkMeMsIDzqUsBaDvdwbt7j3R/29+8\n5zDPbdkPgAS1VSU0RH3bnzqqlKKCxFfxRyLGmUiEM53GmY4IZzojnA7/PdNpnOmM0N4ZCZedfR2J\nGOOHX8LE6pKk2x/ovMg755xLWXFRAVdOGM6VE84+duTg8dNs3nuEzR8Exf/lHa08+dYeAAbli7EV\nl9AZsbBwR2iPKtgdkQu7+LsgT0ysLqFuZGn3LYR1o0p91L+QF3nnnHMXZHhJEddNqea6KdUAmBkf\nHjnFpvAQ/55DJxmULwbl5zGoII/C/Lyzr/PzKIyeVxDOC5d1zTvndX7w2JXmA21s23eUpn1H+UPz\nIZ5+5+zT+SpLCoOCH1X8a6tKKCxI9eGrucGLvHPOuYtKEmPKhzCmfAifuWxUn/2c6WOG8rmG0d2v\nP25rZ9v+o2zbdywo/vuP8sjru2nvCC4eHJQvaqtKqA+/7XcV/1y+gNCLvHPOuZxQUVzInNpK5tRW\nds/r6Iyw80AbjfuC4t+0/ygb3jvAyrf3drepKi2ibmQp9aPKmDW+gqsnVebMBYS5EYVzzjkXR0F+\nHpNGlDJpRCk3zzw7/1BbO037jp5T/Jdv2MXDrzRTmJ/HlROGMb+umvl11Vw6vDh9AVwgL/LOOecG\nnGHFhcyZWMmciWe/9bd3RHhz98esa2rhxaZW7l/VyP2rGqmtKmbB1BFcN6Wa2TUV3dcEZAMv8s45\n5xzBLYNdT/X71l/Vs+tAG+uaWnlpeyvLN+xk2SvNlA4uYO7kKubXBaMGDivO7DH/vcg755xzcdRU\nFnP71Z/g9qs/wfHTHbz25wOsa2phXdNH/HbzPiT45PiK7sP6dSNLM27oXy/yzjnnXA9Kigq4cfpI\nbpw+kkjEePfDI7y4rZV1Ta089Px2Hnp+O6OHDua6umoWTK3OmEf5epF3zjnneiEvT90jAf7Twsm0\nHj3FS9tbeXFbK0+9vZfH3nifooI8rppY2f0tf3T5kLT01Yu8c845dwGqywbzxSvG88UrxnO6o5M3\nmg+xrqm1ewJ4/d/mM2po/xf6lC4RlDRM0lOS2iTtlvTlBO0k6XuSDobT9xR1gkLSTElvSjoR/jsz\n1XWdc865TFdUkM+1k6u473PTePnuebxw11we/MJlaSnwkPo3+f8G2oERwEzgd5I2mdnWmHZfA24B\nGgAD1gI7gaWSCoFngB8BPwP+AXhG0iQza0+27vmH55xzzqWHFIyrP7G6JG196PGbvKRiYBGwxMyO\nm9lrwLPA38Vpvhj4oZntMbO9wA+B28Jl8wg+VPzIzE6b2Y8BAfNTWNc555xzvZTK4frJQIeZ7Yia\ntwmYFqfttHBZvHbTgM1mFv3Ioc0xyxOt65xzzrleSuVwfQlwNGbeEaA0QdsjMe1KwnPrsctit5Nw\n3ZgPBkj6GsHhfYDjkranEEeqKoEDF3F7mSIX48rFmCAD4lrBiou9ybTH1AdyMSbIzbhyMaZLU2mU\nSpE/DpTFzCsDjqXQtgw4bmYmqaftJFw39oeY2TJgWQp97zVJG81sdl9sO51yMa5cjAlyMy6PKXvk\nYly5GFOqUjlcvwMokDQpal4DEHvRHeG8hgTttgIzYq6YnxGzPNG6zjnnnOulHou8mbUBK4EHJBVL\nugq4Gfh1nOaPAndJGiNpNPBN6D7utx7oBP5RUpGkO8P561JY1znnnHO9lOqjdO4AhgCtwOPA181s\nq6RrwsPwXR4GVgFbgHeB34XzCG+TuwX4CnAYuB24JZyfdN1+1ienATJALsaVizFBbsblMWWPXIwr\nF2NKieKc8nbOOedcDsieh+I655xzrle8yDvnnHM5akAW+Ys1Fn+mCC9k/GUYyzFJ70i6KUHb2yR1\nSjoeNc3r5y6nTNJ6Saei+hp3TIQsytXxmKlT0k8StM3YXEm6U9JGSaclrYhZtkBSU/iMipckJbyf\nV1JN2OZEuM71fd75JBLFJelTktZKOiTpI0lPSBqVZDsp7bf9IUlMNZIsZv9akmQ7GZOrJDHdGhPP\niTDGyxNsJ2Py1FcGZJHn3LH4bwV+Line6HrR4+nPAD5LMOZ+pikAPgDmAkOB/wD+T1JNgvavm1lJ\n1LS+X3p5/u6M6uuUBG2yIlfRv3dgJHASeCLJKpmaqw+B7wC/ip4pqZLgbpwlwDBgI/C/SbbzOPA2\nMBz4FvAbSVV90eEUxY0LqCC4eKuGYBCSY8DyHraVyn7bHxLF1KU8qp/fTrKdTMpV3JjM7LGYv7E7\ngGbgrSTbypQ89YkBV+R18cbizxhm1mZm95nZLjOLmNlvCR7uE/fTa47KilzFWERwx8qr6e5Ib5nZ\nSjN7GjgYs+gLwFYze8LMTgH3AQ2S6mK3IWky8EngXjM7aWZPEtxds6hve59YorjMbHUY01EzOwH8\nFLgqLZ3spSS5Slmm5aoXMS0GHo03qNpAMeCKPBdvLP6MJWkEQZyJBhOaJemApB2SlkhK9WmE6fJg\n2N8NSQ5XZ2OuUnkDyrZcnZOHcJyN90j899VsZtGjZ2ZD3gCupefBulLZbzPBbkl7JC0Pj8TEk3W5\nCk8TXUswBksy2ZKn8zIQi/zFGos/I0kaBDwGPGJmTXGavAJMB6oJPoV/Cbi7/3rYa/8CTADGEBwu\nXSWpNk67rMpV+AY0F3gkSbNsyxX0/IyK822bMSTNAO4heS5S3W/T6QBwBcHph8sJfu+PJWibjbn6\nCvCqme1M0iYb8nRBBmKRvyhj8fdR3y6IpDyCkQjbgTvjtTGzZjPbGR7W3wI8APxNP3azV8zsDTM7\nFj6e+BFgA/CZOE2zKlcEp4deS/YGlG25Cl3I31eythlB0kRgNfANM0t4mqUX+23ahKcrN5pZh5m1\nELxn3CApXuHOulwRFPlkH6KzIk8XaiAW+Ys1Fn9GCb+x/pLgYsJFZnYmxVUNyMhvuwkk6m/W5CrU\n4xtQHNmQq3PyEF4DU0viv68JMUUlY/MWHn15Afi2mcUb1juZbMhd1wfieHUh23J1FTAa+E0vV82G\nPPXKgCvyF3Es/kzzc2Aq8FkzO5mokaSbwnP2hBdDLQGe6Z8u9o6kckl/KWmwpAJJtxKcY/t9nOZZ\nkytJcwgODya7qj6jcxXmYzCQD+R35Qh4CpguaVG4/B5gc7xTR+F1Me8A94brf57gzogn+y+ScyWK\nS9IYguds/NTMlvawjd7st30uSUxXSpoiKU/ScODHwHoziz0sn3G5SrL/dVkMPBlzDUHsNjIqT33G\nzAbcRHBrz9NAG/A+8OVw/jUEh3i72gn4PnAonL5POBRwJk0E59QMOEVwWK1ruhUYH/5/fNj2B0BL\nGHszwSHgQemOIUFcVcCfCA4JHgb+ACzM5lyFfX0Y+HWc+VmTK4Kr5i1mui9cdj3QRHB74HqgJmq9\npcDSqNc1YZuTwHbg+kyMC7g3/H/031f0/vfvwOqe9tsMi+lLBHfhtAH7CD4oj8yGXPWw/w0Of+8L\n4qyXsXnqq8nHrnfOOedy1IA7XO+cc84NFF7knXPOuRzlRd4555zLUV7knXPOuRzlRd4555zLUV7k\nnXPOuRzlRd4555zLUV7knXPOuRzlRd4555zLUf8PA9EWcLm51U0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PGZzwLEW_uJ",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwLwugZdXNVC",
        "colab_type": "text"
      },
      "source": [
        "In this exercise we modify the prior example and use a different pre-trained model (Inception_Resnet- V2 w/imagenet dataset). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8eIvy1TXdpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create base mobel from pre-trained MobileNet V2\n",
        "IMG_SHAPE = (image_size, image_size, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model2 = tf.keras.applications.InceptionResNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "base_model2.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY-Unp_NYHiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af220fcd-fff5-447b-c3eb-0eb4b86be802"
      },
      "source": [
        "base_model2.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_resnet_v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 79, 79, 32)   864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 79, 79, 32)   96          conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 79, 79, 32)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 77, 77, 32)   9216        activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 77, 77, 32)   96          conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 77, 77, 32)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 77, 77, 64)   18432       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 77, 77, 64)   192         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 77, 77, 64)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 38, 38, 64)   0           activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 38, 38, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 38, 38, 80)   240         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 38, 38, 80)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 36, 36, 192)  138240      activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 36, 36, 192)  576         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 36, 36, 192)  0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 192)  0           activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 17, 17, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 17, 17, 64)   192         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 17, 17, 64)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 17, 17, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 17, 17, 96)   55296       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 17, 17, 48)   144         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 17, 17, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 17, 17, 48)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 17, 17, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 17, 17, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 17, 17, 96)   18432       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 17, 17, 64)   76800       activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 17, 17, 96)   82944       activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 17, 17, 64)   12288       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 17, 17, 96)   288         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 17, 17, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 17, 17, 96)   288         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 17, 17, 64)   192         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 17, 17, 96)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 17, 17, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 17, 17, 96)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 17, 17, 64)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, 17, 17, 320)  0           activation_208[0][0]             \n",
            "                                                                 activation_210[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "                                                                 activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 17, 17, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 17, 17, 32)   96          conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 17, 17, 32)   0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 17, 17, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 17, 17, 48)   13824       activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 17, 17, 32)   96          conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 17, 17, 48)   144         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 17, 17, 32)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 17, 17, 48)   0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 17, 17, 32)   10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 17, 17, 32)   9216        activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 17, 17, 64)   27648       activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 17, 17, 32)   96          conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 17, 17, 32)   96          conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 17, 17, 64)   192         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 17, 17, 32)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 17, 17, 32)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 17, 17, 64)   0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_215[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, 17, 17, 320)  0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, 17, 17, 320)  0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 17, 17, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 17, 17, 32)   96          conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 17, 17, 32)   0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 17, 17, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 17, 17, 48)   13824       activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 17, 17, 32)   96          conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 17, 17, 48)   144         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 17, 17, 32)   0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 17, 17, 48)   0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 17, 17, 32)   10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 17, 17, 32)   9216        activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 17, 17, 64)   27648       activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 17, 17, 32)   96          conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 17, 17, 32)   96          conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 17, 17, 64)   192         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 17, 17, 32)   0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 17, 17, 32)   0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 17, 17, 64)   0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_221[0][0]             \n",
            "                                                                 activation_223[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, 17, 17, 320)  0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, 17, 17, 320)  0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 17, 17, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 17, 17, 32)   96          conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 17, 17, 32)   0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 17, 17, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 17, 17, 48)   13824       activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 17, 17, 32)   96          conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 17, 17, 48)   144         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 17, 17, 32)   0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 17, 17, 48)   0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 17, 17, 32)   10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 17, 17, 32)   9216        activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 17, 17, 64)   27648       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 17, 17, 32)   96          conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 17, 17, 32)   96          conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 17, 17, 64)   192         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 17, 17, 32)   0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 17, 17, 32)   0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 17, 17, 64)   0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_227[0][0]             \n",
            "                                                                 activation_229[0][0]             \n",
            "                                                                 activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, 17, 17, 320)  0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, 17, 17, 320)  0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 17, 17, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 17, 17, 32)   96          conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 17, 17, 32)   0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 17, 17, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 17, 17, 48)   13824       activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 17, 17, 32)   96          conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 17, 17, 48)   144         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 17, 17, 32)   0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 17, 17, 48)   0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 17, 17, 32)   10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 17, 17, 32)   9216        activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 17, 17, 64)   27648       activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 17, 17, 32)   96          conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 17, 17, 32)   96          conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 17, 17, 64)   192         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 17, 17, 32)   0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 17, 17, 32)   0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 17, 17, 64)   0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_233[0][0]             \n",
            "                                                                 activation_235[0][0]             \n",
            "                                                                 activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, 17, 17, 320)  0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, 17, 17, 320)  0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 17, 17, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 17, 17, 32)   96          conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 17, 17, 32)   0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 17, 17, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 17, 17, 48)   13824       activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 17, 17, 32)   96          conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 17, 17, 48)   144         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 17, 17, 32)   0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 17, 17, 48)   0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 17, 17, 32)   10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 17, 17, 32)   9216        activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 17, 17, 64)   27648       activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 17, 17, 32)   96          conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 17, 17, 32)   96          conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 17, 17, 64)   192         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 17, 17, 32)   0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 17, 17, 32)   0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 17, 17, 64)   0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_239[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, 17, 17, 320)  0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, 17, 17, 320)  0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 17, 17, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 17, 17, 32)   96          conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 17, 17, 32)   0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 17, 17, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 17, 17, 48)   13824       activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 17, 17, 32)   96          conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 17, 17, 48)   144         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 17, 17, 32)   0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 17, 17, 48)   0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 17, 17, 32)   10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 17, 17, 32)   9216        activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 17, 17, 64)   27648       activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 17, 17, 32)   96          conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 17, 17, 32)   96          conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 17, 17, 64)   192         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 17, 17, 32)   0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 17, 17, 32)   0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 17, 17, 64)   0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_245[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "                                                                 activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, 17, 17, 320)  0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, 17, 17, 320)  0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 17, 17, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 17, 17, 32)   96          conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 17, 17, 32)   0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 17, 17, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 17, 17, 48)   13824       activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 17, 17, 32)   96          conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 17, 17, 48)   144         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 17, 17, 32)   0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 17, 17, 48)   0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 17, 17, 32)   10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 17, 17, 32)   9216        activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 17, 17, 64)   27648       activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 17, 17, 32)   96          conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 17, 17, 32)   96          conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 17, 17, 64)   192         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 17, 17, 32)   0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 17, 17, 32)   0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 17, 17, 64)   0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_251[0][0]             \n",
            "                                                                 activation_253[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, 17, 17, 320)  0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, 17, 17, 320)  0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 17, 17, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 17, 17, 32)   96          conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 17, 17, 32)   0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 17, 17, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 17, 17, 48)   13824       activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 17, 17, 32)   96          conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 17, 17, 48)   144         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 17, 17, 32)   0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 17, 17, 48)   0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 17, 17, 32)   10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 17, 17, 32)   9216        activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 17, 17, 64)   27648       activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 17, 17, 32)   96          conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 17, 17, 32)   96          conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 17, 17, 64)   192         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 17, 17, 32)   0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 17, 17, 32)   0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 17, 17, 64)   0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_257[0][0]             \n",
            "                                                                 activation_259[0][0]             \n",
            "                                                                 activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, 17, 17, 320)  0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, 17, 17, 320)  0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 17, 17, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 17, 17, 32)   96          conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 17, 17, 32)   0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 17, 17, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 17, 17, 48)   13824       activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 17, 17, 32)   96          conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 17, 17, 48)   144         conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 17, 17, 32)   0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 17, 17, 48)   0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 17, 17, 32)   10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 17, 17, 32)   9216        activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 17, 17, 64)   27648       activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 17, 17, 32)   96          conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 17, 17, 32)   96          conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 17, 17, 64)   192         conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 17, 17, 32)   0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 17, 17, 32)   0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 17, 17, 64)   0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_263[0][0]             \n",
            "                                                                 activation_265[0][0]             \n",
            "                                                                 activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, 17, 17, 320)  0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, 17, 17, 320)  0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 17, 17, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 17, 17, 32)   96          conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 17, 17, 32)   0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 17, 17, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 17, 17, 48)   13824       activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 17, 17, 32)   96          conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 17, 17, 48)   144         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 17, 17, 32)   0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 17, 17, 48)   0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 17, 17, 32)   10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 17, 17, 32)   9216        activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 17, 17, 64)   27648       activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 17, 17, 32)   96          conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 17, 17, 32)   96          conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 17, 17, 64)   192         conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 17, 17, 32)   0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 17, 17, 32)   0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 17, 17, 64)   0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, 17, 17, 128)  0           activation_269[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "                                                                 activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, 17, 17, 320)  41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, 17, 17, 320)  0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, 17, 17, 320)  0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 17, 17, 256)  81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 17, 17, 256)  768         conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 17, 17, 256)  0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 17, 17, 256)  589824      activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 17, 17, 256)  768         conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 17, 17, 256)  0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 8, 8, 384)    1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 8, 8, 384)    884736      activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 8, 8, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 8, 8, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 8, 8, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 8, 8, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 320)    0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, 8, 8, 1088)   0           activation_275[0][0]             \n",
            "                                                                 activation_278[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 8, 8, 128)    139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 8, 8, 128)    384         conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 8, 8, 128)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 8, 8, 160)    143360      activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 8, 8, 160)    480         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 8, 8, 160)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 8, 8, 192)    208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 8, 8, 192)    215040      activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 8, 8, 192)    576         conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 8, 8, 192)    576         conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 8, 8, 192)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 8, 8, 192)    0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_279[0][0]             \n",
            "                                                                 activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, 8, 8, 1088)   0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, 8, 8, 1088)   0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 8, 8, 128)    139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 8, 8, 128)    384         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 8, 8, 128)    0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 8, 8, 160)    143360      activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 8, 8, 160)    480         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 8, 8, 160)    0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 8, 8, 192)    208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 8, 8, 192)    215040      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 8, 8, 192)    576         conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 8, 8, 192)    576         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 8, 8, 192)    0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 8, 8, 192)    0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_283[0][0]             \n",
            "                                                                 activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, 8, 8, 1088)   0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, 8, 8, 1088)   0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 8, 8, 128)    139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 8, 8, 128)    384         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 8, 8, 128)    0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 8, 8, 160)    143360      activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 8, 8, 160)    480         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 8, 8, 160)    0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 8, 8, 192)    208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 8, 8, 192)    215040      activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 8, 8, 192)    576         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 8, 8, 192)    576         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 8, 8, 192)    0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 8, 8, 192)    0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_287[0][0]             \n",
            "                                                                 activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, 8, 8, 1088)   0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, 8, 8, 1088)   0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 8, 8, 128)    139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 8, 8, 128)    384         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 8, 8, 128)    0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 8, 8, 160)    143360      activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 8, 8, 160)    480         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 8, 8, 160)    0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 8, 8, 192)    208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 8, 8, 192)    215040      activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 8, 8, 192)    576         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 8, 8, 192)    576         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 8, 8, 192)    0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 8, 8, 192)    0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_291[0][0]             \n",
            "                                                                 activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, 8, 8, 1088)   0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, 8, 8, 1088)   0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, 8, 8, 128)    139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 8, 8, 128)    384         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 8, 8, 128)    0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, 8, 8, 160)    143360      activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 8, 8, 160)    480         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 8, 8, 160)    0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, 8, 8, 192)    208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, 8, 8, 192)    215040      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 8, 8, 192)    576         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 8, 8, 192)    576         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 8, 8, 192)    0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 8, 8, 192)    0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_295[0][0]             \n",
            "                                                                 activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, 8, 8, 1088)   0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, 8, 8, 1088)   0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, 8, 8, 128)    139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 8, 8, 128)    384         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 8, 8, 128)    0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, 8, 8, 160)    143360      activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 8, 8, 160)    480         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 8, 8, 160)    0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, 8, 8, 192)    208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, 8, 8, 192)    215040      activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 8, 8, 192)    576         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 8, 8, 192)    576         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 8, 8, 192)    0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 8, 8, 192)    0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_299[0][0]             \n",
            "                                                                 activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, 8, 8, 1088)   0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, 8, 8, 1088)   0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, 8, 8, 128)    139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 8, 8, 128)    384         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 8, 8, 128)    0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, 8, 8, 160)    143360      activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 8, 8, 160)    480         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 8, 8, 160)    0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, 8, 8, 192)    208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, 8, 8, 192)    215040      activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 8, 8, 192)    576         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 8, 8, 192)    576         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 8, 8, 192)    0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 8, 8, 192)    0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_303[0][0]             \n",
            "                                                                 activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, 8, 8, 1088)   0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, 8, 8, 1088)   0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 8, 8, 128)    139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 8, 8, 128)    384         conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 8, 8, 128)    0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 8, 8, 160)    143360      activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, 8, 8, 160)    480         conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 8, 8, 160)    0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, 8, 8, 192)    208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 8, 8, 192)    215040      activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 8, 8, 192)    576         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, 8, 8, 192)    576         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 8, 8, 192)    0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 8, 8, 192)    0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_307[0][0]             \n",
            "                                                                 activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, 8, 8, 1088)   0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, 8, 8, 1088)   0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 8, 8, 128)    139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 8, 8, 128)    384         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 8, 8, 128)    0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 8, 8, 160)    143360      activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 8, 8, 160)    480         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 8, 8, 160)    0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 8, 8, 192)    208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 8, 8, 192)    215040      activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, 8, 8, 192)    576         conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 8, 8, 192)    576         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 8, 8, 192)    0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 8, 8, 192)    0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_311[0][0]             \n",
            "                                                                 activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, 8, 8, 1088)   0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, 8, 8, 1088)   0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 8, 8, 128)    139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 8, 8, 128)    384         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 8, 8, 128)    0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 8, 8, 160)    143360      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 8, 8, 160)    480         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 8, 8, 160)    0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 8, 8, 192)    208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 8, 8, 192)    215040      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 8, 8, 192)    576         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 8, 8, 192)    576         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 8, 8, 192)    0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 8, 8, 192)    0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_315[0][0]             \n",
            "                                                                 activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, 8, 8, 1088)   0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, 8, 8, 1088)   0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 8, 8, 128)    139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 8, 8, 128)    384         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 8, 8, 128)    0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 8, 8, 160)    143360      activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 8, 8, 160)    480         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 8, 8, 160)    0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 8, 8, 192)    208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 8, 8, 192)    215040      activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 8, 8, 192)    576         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 8, 8, 192)    576         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 8, 8, 192)    0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 8, 8, 192)    0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_319[0][0]             \n",
            "                                                                 activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, 8, 8, 1088)   0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, 8, 8, 1088)   0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 8, 8, 128)    139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 8, 8, 128)    384         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 8, 8, 128)    0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 8, 8, 160)    143360      activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 8, 8, 160)    480         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 8, 8, 160)    0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 8, 8, 192)    208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 8, 8, 192)    215040      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 8, 8, 192)    576         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 8, 8, 192)    576         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 8, 8, 192)    0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 8, 8, 192)    0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_323[0][0]             \n",
            "                                                                 activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, 8, 8, 1088)   0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, 8, 8, 1088)   0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 8, 8, 128)    139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 8, 8, 128)    384         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 8, 8, 128)    0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 8, 8, 160)    143360      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 8, 8, 160)    480         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 8, 8, 160)    0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 8, 8, 192)    208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 8, 8, 192)    215040      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 8, 8, 192)    576         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 8, 8, 192)    576         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 8, 8, 192)    0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 8, 8, 192)    0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_327[0][0]             \n",
            "                                                                 activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, 8, 8, 1088)   0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, 8, 8, 1088)   0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 8, 8, 128)    139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 8, 8, 128)    384         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 8, 8, 128)    0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 8, 8, 160)    143360      activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 8, 8, 160)    480         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 8, 8, 160)    0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 8, 8, 192)    208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 8, 8, 192)    215040      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 8, 8, 192)    576         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 8, 8, 192)    576         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 8, 8, 192)    0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 8, 8, 192)    0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_331[0][0]             \n",
            "                                                                 activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, 8, 8, 1088)   0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, 8, 8, 1088)   0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 8, 8, 128)    139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 8, 8, 128)    384         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 8, 8, 128)    0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 8, 8, 160)    143360      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 8, 8, 160)    480         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 8, 8, 160)    0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 8, 8, 192)    208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 8, 8, 192)    215040      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 8, 8, 192)    576         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 8, 8, 192)    576         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 8, 8, 192)    0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 8, 8, 192)    0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_335[0][0]             \n",
            "                                                                 activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, 8, 8, 1088)   0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, 8, 8, 1088)   0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 8, 8, 128)    139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 8, 8, 128)    384         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 8, 8, 128)    0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 8, 8, 160)    143360      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 8, 8, 160)    480         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 8, 8, 160)    0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 8, 8, 192)    208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 8, 8, 192)    215040      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 8, 8, 192)    576         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 8, 8, 192)    576         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 8, 8, 192)    0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 8, 8, 192)    0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_339[0][0]             \n",
            "                                                                 activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, 8, 8, 1088)   0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, 8, 8, 1088)   0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 8, 8, 128)    139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 8, 8, 128)    384         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 8, 8, 128)    0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 8, 8, 160)    143360      activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 8, 8, 160)    480         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 8, 8, 160)    0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 8, 8, 192)    208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 8, 8, 192)    215040      activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 8, 8, 192)    576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 8, 8, 192)    576         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 8, 8, 192)    0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 8, 8, 192)    0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_343[0][0]             \n",
            "                                                                 activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, 8, 8, 1088)   0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, 8, 8, 1088)   0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 8, 8, 128)    139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 8, 8, 128)    384         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 8, 8, 128)    0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 8, 8, 160)    143360      activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 8, 8, 160)    480         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 8, 8, 160)    0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 8, 8, 192)    208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 8, 8, 192)    215040      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 8, 8, 192)    576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 8, 8, 192)    576         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 8, 8, 192)    0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 8, 8, 192)    0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_347[0][0]             \n",
            "                                                                 activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, 8, 8, 1088)   0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, 8, 8, 1088)   0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 8, 8, 128)    139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 8, 8, 128)    384         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 8, 8, 128)    0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 8, 8, 160)    143360      activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 8, 8, 160)    480         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 8, 8, 160)    0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 8, 8, 192)    208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 8, 8, 192)    215040      activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 8, 8, 192)    576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 8, 8, 192)    576         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 8, 8, 192)    0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 8, 8, 192)    0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_351[0][0]             \n",
            "                                                                 activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, 8, 8, 1088)   0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, 8, 8, 1088)   0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 8, 8, 128)    139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 8, 8, 128)    384         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 8, 8, 128)    0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 8, 8, 160)    143360      activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 8, 8, 160)    480         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 8, 8, 160)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 8, 8, 192)    208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 8, 8, 192)    215040      activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 8, 8, 192)    576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 8, 8, 192)    576         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 8, 8, 192)    0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 8, 8, 192)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_355[0][0]             \n",
            "                                                                 activation_358[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, 8, 8, 1088)   0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, 8, 8, 1088)   0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 8, 8, 256)    278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 8, 8, 256)    768         conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 8, 8, 256)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 8, 8, 256)    278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 8, 8, 256)    278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, 8, 8, 288)    663552      activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 8, 8, 256)    768         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 8, 8, 256)    768         conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, 8, 8, 288)    864         conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 8, 8, 256)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 8, 8, 256)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, 8, 8, 288)    0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 3, 3, 384)    884736      activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 3, 3, 288)    663552      activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, 3, 3, 320)    829440      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 3, 3, 384)    1152        conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 3, 3, 288)    864         conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, 3, 3, 320)    960         conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 3, 3, 384)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 3, 3, 288)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, 3, 3, 320)    0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 1088)   0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, 3, 3, 2080)   0           activation_360[0][0]             \n",
            "                                                                 activation_362[0][0]             \n",
            "                                                                 activation_365[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, 3, 3, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, 3, 3, 192)    576         conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 3, 3, 192)    0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, 3, 3, 224)    129024      activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, 3, 3, 224)    672         conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 3, 3, 224)    0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, 3, 3, 192)    399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, 3, 3, 256)    172032      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, 3, 3, 192)    576         conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, 3, 3, 256)    768         conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, 3, 3, 192)    0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 3, 3, 256)    0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_366[0][0]             \n",
            "                                                                 activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, 3, 3, 2080)   0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, 3, 3, 2080)   0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, 3, 3, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, 3, 3, 192)    576         conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 3, 3, 192)    0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, 3, 3, 224)    129024      activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, 3, 3, 224)    672         conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 3, 3, 224)    0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, 3, 3, 192)    399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, 3, 3, 256)    172032      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, 3, 3, 192)    576         conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, 3, 3, 256)    768         conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 3, 3, 192)    0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 3, 3, 256)    0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_370[0][0]             \n",
            "                                                                 activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, 3, 3, 2080)   0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, 3, 3, 2080)   0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, 3, 3, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, 3, 3, 192)    576         conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 3, 3, 192)    0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, 3, 3, 224)    129024      activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, 3, 3, 224)    672         conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 3, 3, 224)    0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, 3, 3, 192)    399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 3, 3, 256)    172032      activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, 3, 3, 192)    576         conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 3, 3, 256)    768         conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 3, 3, 192)    0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 3, 3, 256)    0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_374[0][0]             \n",
            "                                                                 activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, 3, 3, 2080)   0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, 3, 3, 2080)   0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 3, 3, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 3, 3, 192)    576         conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 3, 3, 192)    0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 3, 3, 224)    129024      activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 3, 3, 224)    672         conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 3, 3, 224)    0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 3, 3, 192)    399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 3, 3, 256)    172032      activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 3, 3, 192)    576         conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 3, 3, 256)    768         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 3, 3, 192)    0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 3, 3, 256)    0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_378[0][0]             \n",
            "                                                                 activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, 3, 3, 2080)   0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, 3, 3, 2080)   0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 3, 3, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 3, 3, 192)    576         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 3, 3, 192)    0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 3, 3, 224)    129024      activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 3, 3, 224)    672         conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 3, 3, 224)    0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 3, 3, 192)    399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 3, 3, 256)    172032      activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 3, 3, 192)    576         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 3, 3, 256)    768         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 3, 3, 192)    0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 3, 3, 256)    0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_382[0][0]             \n",
            "                                                                 activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, 3, 3, 2080)   0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, 3, 3, 2080)   0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 3, 3, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 3, 3, 192)    576         conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 3, 3, 192)    0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 3, 3, 224)    129024      activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 3, 3, 224)    672         conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 3, 3, 224)    0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 3, 3, 192)    399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 3, 3, 256)    172032      activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 3, 3, 192)    576         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 3, 3, 256)    768         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 3, 3, 192)    0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 3, 3, 256)    0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_386[0][0]             \n",
            "                                                                 activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, 3, 3, 2080)   0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, 3, 3, 2080)   0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 3, 3, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 3, 3, 192)    576         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 3, 3, 192)    0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 3, 3, 224)    129024      activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 3, 3, 224)    672         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 3, 3, 224)    0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 3, 3, 192)    399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 3, 3, 256)    172032      activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 3, 3, 192)    576         conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 3, 3, 256)    768         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 3, 3, 192)    0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 3, 3, 256)    0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_390[0][0]             \n",
            "                                                                 activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, 3, 3, 2080)   0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, 3, 3, 2080)   0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 3, 3, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 3, 3, 192)    576         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 3, 3, 192)    0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 3, 3, 224)    129024      activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 3, 3, 224)    672         conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 3, 3, 224)    0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 3, 3, 192)    399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 3, 3, 256)    172032      activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 3, 3, 192)    576         conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 3, 3, 256)    768         conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 3, 3, 192)    0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 3, 3, 256)    0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_394[0][0]             \n",
            "                                                                 activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, 3, 3, 2080)   0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, 3, 3, 2080)   0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 3, 3, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 3, 3, 192)    576         conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 3, 3, 192)    0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 3, 3, 224)    129024      activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 3, 3, 224)    672         conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 3, 3, 224)    0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 3, 3, 192)    399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 3, 3, 256)    172032      activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 3, 3, 192)    576         conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 3, 3, 256)    768         conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 3, 3, 192)    0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 3, 3, 256)    0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_398[0][0]             \n",
            "                                                                 activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, 3, 3, 2080)   0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, 3, 3, 2080)   0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 3, 3, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 3, 3, 192)    576         conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 3, 3, 192)    0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 3, 3, 224)    129024      activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 3, 3, 224)    672         conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 3, 3, 224)    0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 3, 3, 192)    399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 3, 3, 256)    172032      activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 3, 3, 192)    576         conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 3, 3, 256)    768         conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 3, 3, 192)    0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 3, 3, 256)    0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, 3, 3, 448)    0           activation_402[0][0]             \n",
            "                                                                 activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, 3, 3, 2080)   933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, 3, 3, 2080)   0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, 3, 3, 1536)   3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, 3, 3, 1536)   4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, 3, 3, 1536)   0           conv_7b_bn[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 54,336,736\n",
            "Trainable params: 0\n",
            "Non-trainable params: 54,336,736\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0KPGL1IYlpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "  base_model2,\n",
        "  keras.layers.GlobalAveragePooling2D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v-sss_wYsfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f1acb438-7942-4479-d45e-853042e5b63e"
      },
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model2.summary()\n",
        "len(model2.trainable_variables)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inception_resnet_v2 (Model)  (None, 3, 3, 1536)        54336736  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1537      \n",
            "=================================================================\n",
            "Total params: 54,338,273\n",
            "Trainable params: 1,537\n",
            "Non-trainable params: 54,336,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjgpD3kbY5wC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1bfc4533-6e17-42d9-d274-c15e5b6bcfce"
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs,\n",
        "                              workers=4,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_steps)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "62/62 [==============================] - 18s 286ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.2562 - val_acc: 0.9496\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 8s 122ms/step - loss: 0.0135 - acc: 0.9970 - val_loss: 0.1725 - val_acc: 0.9688\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 8s 122ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1033 - val_acc: 0.9718\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 8s 123ms/step - loss: 0.0095 - acc: 0.9964 - val_loss: 0.1073 - val_acc: 0.9778\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 8s 126ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.1072 - val_acc: 0.9798\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 8s 124ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.1502 - val_acc: 0.9768\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 8s 124ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.1031 - val_acc: 0.9798\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 8s 125ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1142 - val_acc: 0.9798\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 8s 125ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.1226 - val_acc: 0.9758\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 8s 125ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.1646 - val_acc: 0.9718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNL4QrxyY6LF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "7f1a67ff-7be0-4835-965d-871a7c2614b0"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAHlCAYAAABoLv9VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}